#### 物流

我叫曹雨薇，来自湖南常德，本科的专业是计算机科学与技术专业，至今已经有2年多的工作经验了，有扎实的java基础，熟悉JUC多线程，了解JVM内存结构以及垃圾回收机制，熟练使用mysql关系型数据库以及redis非关系型数据库，熟练掌握主流框架，比如SpringMVC、SpringBoot、SpringCloud、mybatis、mybatisPlus这些常用框架。了解redis、mq、还有一些微服务常用的中间件，在项目中都有过实践。

我最近完成的是物流项目，主要分为四个端：司机端、用户端、管理端、快递员端。用户通过小程序进行下单，生成订单创建揽件任务，快递员取件之后，用户对订单进行支付，产生交易单，创建运单，快递开始运输，经过运输流转，生成多个运输单，最终到达网点，快递员派件，用户签收，拒收。主要用到的技术是Springcloud，mybatis、xxl-job、redis、mq、nacos、gateway、feign、nginx、jwt、oss等



##### 1、双token三验证

①用户登录，后台生成两个token，一个accessToken 一个refreshToken，其中accessToken设置5分钟，refreshToken设置24小时 并存储在redis中

②把生成的两个token传给前端，前端请求数据接口的时候携带accessToken进行校验，校验成功返回结果

③校验失败返回401，,刷新token，携带refreshToken进行校验，校验失败重新登录，校验成功就去判断redis中的refreshToken是否已经被使用，无效重新登录，有效就重新生成accessToken、refreshToken返回给前端，并刷新redis中的refreshToken



##### 2、分布式锁处理幂等性

①一个逻辑只需要处理一次，但是因为某种原因导致发出了多个请求，逻辑可能会被重复处理，为了避免这种情况的发送，这里使用了分布式锁进行处理

②通过redis中的setnx作为分布式锁，对key进行判断，如果key存在返回0，key不存在返回1

③这里是使用redissionClient获取一个公平锁，调用tryLock()尝试去获取锁执行业务逻辑，否则就抛出异常，需要再finally中释放锁

④如果程序还未执行完，锁就已经释放了。这里使用的redissionClient里面会自动开启一个看门狗机制，扫描到程序执行1/3，如果当前线程还持有锁，就自动刷新到30s，保证程序在执行完之前锁是有效的



##### 3、创建模板

①根据不同的模板进行不同的运费计算，主要有同城寄、省内寄、省外寄、经济区互寄

②模板表主要字段有：模板id、模板类型、轻抛系数、首重续重、关联城市

③其中轻抛系数是指体积/轻抛系数=重量，两个重量去最大值。关联城市主要是对经济区互寄的城市进行记录

④根据条件去查询模板，判断是否为经济区互寄

- 如果是就查看关联城市是否存在，存在抛出异常401，不存在就进行新增数据
- 如果不是就查看模板是否存在，存在就查看是否是新增操作，如果不是就更改数据，如果是就抛出异常401


4、查找模板

①使用的是责任链模式去查找模板，根据不同的模板处理不同的逻辑，如果使用多个if进行嵌套不符合开发的一个规范

②首先定义一个抽象类模板链，其中有doNextHandler执行下一个模板（判断是否为最后一个或者是已经找到模板）、setNextHandler设置下一个模板

③为模板定义实体类并继承抽象类模板链

- 同城：判断发件人和收件人的id是否在同一个城市，如果在就返回doNextHandler
- 省内：和同城差不多
- 经济区互寄：经济区是由多个城市进行 组合，设置经济区枚举 是个map，通过判断收件人和发件人的id，判断判断收件人和发件人的城市是否在同一个枚举中，如果在的话就判断为经济区互寄
- 跨省：直接判断，进行返回



##### 5、同步支付功能

①快递员向用户展示二维码，用户扫描二维码，返回支付结果给第三方平台，那我们怎么知道支付状态呢，这里是通过异步通知、主动查询两种方案

②其中异步通知是支付微服务异步通知我们支付的状态，但是由于网络的不稳定性，异步通知出现故障，所以需要使用定时任务主动查询的方式，去查询支付中的订单

③异步通知

- 支付宝：获取支付参数——通过验签的方式验证请求是否来自支付宝——SDK对参数进行校验——获取交易单号——更新交易单（传递参数：交易单号、支付结果。里面有一个redission进行并发处理，判断是否已经结算，如果已经结算就设置支付成功，清空二维码数据。使用mq异步的方式通知其他服务已经支付成功，最后返回响应码结果）
- 微信：获取请求头——构建请求参数——加载验签——验证成功后执行逻辑——返回null

④主动查询

- 这里使用的是xxl-job定时任务调度，分片广播的方式去查询支付状态，并行做任务不重复
- 查看支付中状态——如果订单状态!=付款中——拿到交易单号%分片节点总数=当前节点下标（判断这个节点是否需要处理任务）——如果是就相当于已经支付并修改支付状态——通过mq异步的方式去通知其他系统已经支付成功



##### 6、机构同步

①机构类型分为：一级转运中心、二级转运中心、网点。

②我们是使用的中台权限管家对机构进行增删改，操作后需要在路线微服务中进行同步，采用mq异步的方式进行同步

③比如用户在权限管家中新增机构，权限管家保存数据，权限管家需要发消息给路线微服务，路线微服务进行相应的业务，保存数据到neo4j

- 权限管家发消息：通过在配置文件中配置交换机、交换机类型
- 路线微服务监听消息：解析传来的json，根据后缀名去判断机构的机构类型，设置对应的实体和服务，通过JPA对neo4j进行相应的增删改





##### 7、美团Leaf生成订单号

①因为对生成的订单号有特殊的要求，所有没有使用雪花算法（19位）

②这里使用的是美团Leaf生成订单号，是基于一张表进行实现，每次获取一个号段，生成的id在内存中自增长，号段用完之后，再从数据库更新

③表内容：业务标签、号段最大id、号段长度、描述、更新时间

④在配置文件中配置leaf——根据规则拼接url——生成自定义id——直接通过getId进行获取

⑤双buffer：网络阻塞，导致下一个号段获取失败，所以当号段使用了10%的时候，就会创建一个线程去获取另外一个号段，这个号段用完了就直接切换到下一个号段



##### 8、订单转运单

① 用户下单，快递员收件（进行幂等性处理，判断订单id、运单id是否存在。通过订单详情校验体积、重量、收货人位置）

②校验成功生成运单号，查看是否为同一网点

- 同一网点：不需要任务调度，发送更新订单的消息，生成派件任务，发消息给其他服务
- 不同网点：需要调度，发消息给调度中心，创建运单对象进行存储（运单id、机构id、下一个机构id、总体积、重量、状态）



##### 9、合并运单

①快递的收货点和发货点可能不同，当可能存在相同的转运节点，需要对相同的转运节点有顺序的进行合并，从而节约成本

②这里是使用的redis的List作为队列，LPust放入队列，Rpop弹出，并删除执行完的队列

③消费者监听，将json类型转化为对象（获取当前节点id、下一个节点id、运单id），key=起始点id，value=运单数据（运单id）

④将相同的转运节点放入同一个队列中，放入：opsForList.leftPush.

如果重复消费，进行幂等性处理。使用set来存储key=起始点id  value=订单id  通过isMember判断是否是成员，存在直接返回



##### 10、项目中的难题

本来物流信息存储在mysql中，一个运单号对应多条不同状态的运单消息（已取件、运输中、派件中、已签收），每一个物流信息对应一条行数据，查询的时候需要做排序，但是在后面数据量大查询频率高，导致效率变慢影响性能

后面使用mongoDB进行存储，mongDB是分布式文件存储的数据库，类似于json结构，适合存储比较复杂的数据类型

把物流信息通过json的形式存储到mongDB中，相当于一条数据，如果有新的物流信息需要加入，直接向infoList插入元素就可以，查询的话就听过transportOrderId查询

（如果有比较复杂的表与表之间关系比较复杂的查询，使用mysql比较合适）

transportOrderId

infoList：创建时间、详情信息、状态





caffeine---redis---mongdb

查询时候可能会存在高并发问题，查询接口增加缓存，减轻持久层的压力

通过多级缓存解决并发：

（nginx加lua脚本去redis中查询 未完成）

第一次查询未命中查询mongdb，第二次查询命中查询一级缓存

①一级缓存：tomcat jvm进程缓存作为一级缓存 使用caffeine（进程级的缓存框架）

- 导入依赖、配置参数：初始容量    最大容量
- 定义config配置文件、配置数据、注入bean

caffeine内存驱逐策略：lfu删除不常用  有效时间   设置为软引用（不太好）



②二级缓存：redis作为二级缓存

- 使用SpringCache进行缓存数据的存储和读取
- SpringCache默认使用jdk的序列化方式缓存数据到redis中，阅读不方便，对redisCacheManager进行配置，使用json格式序列化

在添加缓存数据方法上添加@Cacheable注解



缓存不一致问题

- 方法一：使用 @CachePut(value = "transport-info", key = "#p0") 更新缓存数据，只要mongdb中更新，reids就会更新，删除一级缓存的数据，用户查询时查询到二级缓存    更新到caffeine中（只适合单体架构）
- 方法二：在多集群的环境下，让每个节点接收到消息就可以了，如果用mq就需要在每一个caffeine中设置消息队列，来监听消息，占用不少资源，太浪费了。其实本质就是redis更新了，没有通知另外一个节点的caffeine，使用的是redis中的发布订阅功能，相当于简化版的mq。删除caffeine——redis更新后发起通知——caffeine订阅redis的消息，这个时候caffeine中的数据也会更新













#### CRM



##### 1、首页数据展示

①基础数据：封装VO（线索、商机、合同、销售 金额）

②今日简报：通过创建日期=当前日期进行count

③排行：降序排序，限制展示10条记录



##### 2、线索转商机

①主要涉及到两张表，一张线索表，一张商机表

②前端会传来一个id，根据id找到这条检索，其实我们为了方便下次跟进会设置下次跟进时间，由于我们这条线索已经转为商家了，所有我们就会调用对应的方法，将下次跟进时间设置为空，其实线索与商机的大部分属性相同，通过属性拷贝然后这是一些不一样的参数，添加至商机表，默认把商机分配给管理员



如果转商机失败超过三次就会被记录成伪线索，如果判断为伪线索超过两次就会删除客户信息



##### 3、商机转合同

①前端传来商机id和合同实体，通过商机id查询出商机的信息，合同里面必须要有购买的课程

②首先我们会去判断这个商机里面有没有课程的id，如果没有就抛出异常，如果有就会将商机的状态转换为客户

③在商机表中进行更新，然后对这个商机和合同进行属性拷贝，传入一些两者不同的参数，最后将合同保存到我们的合同表中



##### 4、商机退回公海池

①判断商机是正常商机还是在公海池

②前端会传来一个商机id和商机退回公海池的一个原因，我们只需要通过商机id查询到这条信息的基本信息，将商机的基本状态改为在公海池就可以了



##### 5、OSS

①在配置文件中定义相关配置

②创建OSSUtiles在SDK中复制

③创建一个上传图片的接口——获取原始文件名称——截取后缀——构造新的图片名称——调用ossUtile进行图片上传



##### 6、缓存主页数据

①查询量比较大的时候，如果查询相同数据，只需要查询一次数据库，将数据缓存到redis中，下次查询的时候就直接从缓存中获取就可以了

②首先查看redis中是否有数据，如果存在就直接返回，不存在再去查询数据库，再将查询到的数据存到redis中



##### 7、AOP数据权限

①数据权限的目的就是同一个接口不同角色看到的数据也不同，那么核心就是进行sql的拼接

②使用的是AOP+自定义注解实现数据权限功能。系统中数据权限是与角色进行绑定，所以在角色表中添加了数据权限字段

④在AOP中配置了一个切入点：加了@DateScope注解的方法为切入点

使用前置通知对aop进行增强，也就是说业务在执行之前都会执行AOP里面的逻辑

数据过滤：

- 全部数据：超级管理员是可以查看到全部权限的不需要进行sql拼接
- 自定义数据权限：自定义的是部门，哪些部门的数据权限，通过角色部门关联表 查询出对应相关的部门id，查询相关部门数据
- 本部门及以下：在部门表中，有一个字段是当前部门的所有父节点，当前登录用户的id查询部门表所有包含了该用户部门id的所有部门id，拿到部门id集合，再去查询分配记录表的数据
- 个人数据：获取当前登录的用户id，根据用户id查询分配记录表，分配表中的用户id与登录人的用户id匹配，则表示当前数据属于当前登录人

④mybatis框架需要将拼接好的sql传到xml中进行执行，在这里系统所有的类都继承了baseEntity里面有一个map集合，将这个拼接好的sql传入这个map集合中，在xlm中判断传入map的key是否为空，value为不同权限的sql。如果不为空就在原有的sql上进行拼接



#### 酒店

##### 1、微信登录

①前端登录请求，获取授权码发送给后台

②后台接收到了授权码，调用微信服务接口，获取用户的openid

③通过openid来判断是否为新用户（查看user表中openid字段是否为空），如果为空就自动注册（设置openid、创建时间等字段，进行插入操作），如果存在就进行登录操作

④后台返回给前端一个登录成功的状态，前端把登录状态进行存储

⑤每次发出请求都会携带token进行验证，后台进行解析，合格就返回业务数据



##### 2、酒店搜索

酒店和房型1：n

1. 在es中创建索引相当于mysql中的表，给索引创建字段（id、图片、价格、描述、名称），考虑字段是否分词，分词text，不分词keyword
2. 创建完成之后，把msql中的数据批量导入es
3. 如果mysql里面的数据进行了增加，需要进行数据之前的同步，一个酒店服务，一个搜索服务
4. 使用rabbitmq进行数据之前的同步，酒店发送消息给对应的交换机，通过队列传递消息给消费者搜索服务，es进行相应新增
5. 这就是简单查询，使用的是highLevel的客户端，查询的时候创建boolean查询，因为是组合查询，比如说match、range这些组合起来，如果还需要过滤，就可以使用filter进行过滤（不参与打分），竞价排名，进行相关算分，在查询之上再去进行一个加权

##### 2、分页查询、排序

创建索引库--映射数据库字段关系--将mysql中的数据导入到es--查询条件

1. 准备request->source(DSL)
2. 获取前端传来的页面、页面大小。request.source().from((page-1)*size).size(size)。
3. 排序：sort中指定排序字段，指定降序升序
4. 使用restHighLevelClient发出请求，解析结果



##### 3、高亮显示

1. 高亮字段一定要全文检索，通过highlight的fields指定高亮的字段。通过<em>标签来标记高亮的字段
2. 高亮：.highlighter中的filed指定。如果filed是name，就需要让requireFieldMatch(false)
3. 发送请求，解析结果



##### 4、查询过滤项

1. 多条件查询使用boolean，关键词放到must中。其他过滤条件放入filter
2. 构建QueryBuilders.boolQuery()查询
3. 如果是keyword类型使用term查询。数值类型使用



##### 5、周边查询

1. 前端传来location坐标里面包括经纬度，如果location有值，添加根据geo_distance排序的功能
2. geo_distance里面指定location和前端传来的经纬度。进行排序





##### 6、Freemarker详情页存minio

freemarker是静态的模板，就是模板+数据。导入相关依赖、编写配置文件

准备模板数据和模板，注入configuration读取模板，使用模板对象载入模板类型，生成文件，转成文件流写入minio







#### 外卖

##### 1、用户登录

①前端传来用户的信息，查看数据库进行对比，看用户是否存在

②数据库中的密码是通过用户的密码和盐值进行加密 ，再进行密码的对比

③如果用户名和密码匹配，则登录成功 携带token 返回前端

④其中每一次登录都会携带token，来验证身份是否合法



##### 2、微信登录

①获取用户信息，发送登录请求并携带授权码

②调用微信接口服务，获取用户的openid

③通过openid来判断是否为新用户（user表中openid字段是否为空），如果为空进行自动注册（设置openid,创建时间等字段，进行插入操作）如果是openid存在就进行登录操作

③携带token，登录成功



##### 3、加入购物车

①获得当前用户的购物车

②查看购物车中的数据，如果商品不存在，购物车表中的number字段设置为1，进行插入操作

③如果商品存在，设置number字段+1，进行修改操作



##### 4、用户下单

①用户下单涉及到两张表：订单表、订单详情表。用户进行下单，发送下单请求给后台

②获取当前用户的购物车，封装订单数据，对order表进行插入操作

③向订单详情表插入n条商品的数据，这里是1对多的关系，sql中需要设置collection进行遍历，需要设置主键返回useGeneratedKeys="true" keyProperty="id"

④订单批量插入之后，需要清空购物



##### 5、微信支付功能

①微信用户通过小程序进行下单，返回订单号信息

②小程序向后台发出微信支付的请求，后台调用微信支付的接口，返回预支符标识，将数据组合起来进行签名（签名作用：保证请求的完整性和真实性 防止伪造）

③后端返回支付参数给微信小程序，用户进行微信支付（用户直接和微信沟通 任何支付方式都与后台无关）

④后端返回支付结果给小程序，显示支付结构

⑤支付成功后，需要修改订单的状态



如果收到重复的回调：直接查看状态，如果状态改变就不做任何处理

如果出现网络字段：进行定时 如果支付状态超过定时的时间   重新调用支付的api  来查看支付的结果  



##### 6、redis缓存菜品

①查询数据数据大时，我们可以使用缓存来提高效率，第一次查询时 查询数据库，再次查询时就不用查询数据库，直接从缓存中拿数据

②通过id构造redis中的key

③查询redis中是否有商品数据

④如果存在就直接从redis中拿数据，如果不存在，就对数据库进行查询，将查询中的数据存入redis中



redis与数据库保持一致：
清理缓存

##### 7、起售停售

①前端传来状态、id参数

②状态在数据库中的字段为status，修改状态对商品进行启用禁用操作


















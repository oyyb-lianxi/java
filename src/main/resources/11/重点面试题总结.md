# 基础

我叫欧阳，湖南娄底人，本科毕业于湖南科技学院，大学学的专业是信息与计算科学，现在有6年多的工作经验。有扎实的java基础，熟悉mysql、redis另外orcle、pgsql、ES数据库也都用过，理解事务机制。有过sql优化经验。有了解过冒泡/快排/选择排序/广度优先搜索算法。

对于当前主流的技术框架都有过了解与实践，比如说spring，springboot，springcloud、mybatis，消息中间件等。对于jvm内存结构和juc并发编程也有过研究。

我最近一家公司做的项目是：

华为智能汽车crm管理系统：该项目主要是对企业销售人员提供客户管理的服务。我在该项目中开发工作主要是客户活动/客户计划/客户洞察模块开发：活动与计划相关评论与点赞功能，活动计划邮件推送功能。另外担任客户&客户关系小组的项目PL 其中管理工作主要负责项目迭代计划管理、每日早会、项目代码检视、项目上线checkList、上线后的总结回顾。

主要用到的技术是灵雀平台 + Springboot、mybatis、pgsql、redis、ES、rabbitMq。

评论点赞功能涉及表：

邮件推送功能：

之前一家公司：云策平台跟魔卡实验室：云策平台是一个公司的对用户申请信用卡做可视化规则生成的平台。用户管理/权限管理/决策流/私有库规则流相关功能。

魔卡实验室是公司的可视化绩效管理平台。可视化数据模块开发，相关预警模块开发。

Spring Boot+ MyBatis+ Orcale+mysql+ kafka+Redis + RabbitMQ

用户权限功能实现：



在项目中有解决过慢sql问题，有做过部分·代码重构



当时是客户新闻的需求的迭代二出现的。迭代二开发直接把同一个接口给到了另外一个场景使用 ，没有做需求分析。后面我们做版本回顾主要有三个原因：第一BA在需求交接的时候没有告知开发生产环境数据量的大小。第二 开发自己没有考虑性能问题，需求分析没有做到位。第三：测试场景不到位。

解决办法：

拆分业务，将列表查询跟卡片查询区分开。

优化业务逻辑，将分页查询需要的数据量总数跟数据并行查询。

优化sql：去掉不需要的查询字段，修改子查询为join，连表查询时候小表驱动大表，添加覆盖索引。



登录相关代码重构:

​	通过抽象工厂+策略设计模式重构有多个情景的代码：根据不同情况登录。

创建一个接口，把不同类型的登录情况分成不同的方法实现。





另外在项目中有根据CSA思想以及redis分布式锁 设计实现过分布式客户NUMBER。

先查询number是否存在，不存在则利用redis上锁并且设置过期时间，上锁成功则查询当前数据库number的最大值。并且在修改前再次确认锁存在。

如果上锁失败则 自旋等待500ms再次获取 且设置自旋次数。

最后成功则释放锁，失败则抛出自定义异常。





## 1、JDK\JRE\JVM

- jdk（java开发工具包）里面包括：jre（java运行环境）+开发工具
- 其中jre包括jvm（java虚拟机）+核心类库





## 1、JVM的内存模型

①类加载器：加载class文件

②执行引擎：执行指令，提交操作系统执行

③运行时数据区：在程序运行时，存储数据的内容

 运行时数据区又分为：

  虚拟机栈、本地方法栈、堆、程序计数器、元空间

- 虚拟机栈：保存一些局部变量、方法、运行的数据
- 本地方法栈：用来保存native方法
- 堆：所有新建的对象和数组都会存储到堆中
- 程序计数器：所有线程都要一个程序计数器，就是一个指针，指向方法区的方法字节码，记录行数
- 元空间：虚拟机加载的字节码数据、静态变量、常量、运行时的常量池



##### 1、什么是字节码

我们写的是.java文件------会编译成.class字节码文件。可以做到一次编译到处运行（跨平台），另外一方面可以提高代码执行性能



##### 1、类加载器的过程

①加载：jvm会编译成.class文件加载到内存

②连接：

- 验证：有些人的.class文件是通过自己编译的，可能会不符合jvm编译规则，所以需要确保类加载的正确性
- 准备：为类的静态变量分配内存，将其初始化为默认值。例：int类型的初始值为0
- 解析：把类中的符号引用转化为直接引用。 符号引用：方法a中引用方法b，这个方法b就是符号引用。b指向b方法的内存地址这是不完整的。这里的b只是一个符号引用。指针用的才是真正负责方法调用。

⑤初始化：为类的静态变量赋予正确的初始值。这次才是真正的初始化值。



###### 双亲委派机制

Application----extension---bootStrap

①当Application ClassLoader收到一个类加载请求时，会先交给父类加载器extension classLoader去完成

②extension classLoader收到一个类加载请求时，会先交给BootStrap ClassLoader去完成

③如果BootStrap ClassLoader加载失败，会让extension classLoader加载

④如果extension classLoader加载失败，会让Application ClassLoader加载

⑤如果Application ClassLoader加载失败，会使用自定义加载器尝试加载

⑥如果均失败，则会抛出classNotFoundException异常



使用：

- 继承classLoader类，实现自己的类加载器
- 重写findClass方法，实现双亲委派
- 重写loadClass方法，破坏双亲委派

为什么要使用双亲委派机制：避免重复加载，父类已经加载，子类没必要加载



##### 1、栈

存放类型变量和对象的引用变量。

栈中的数据都是以栈帧存在

栈帧包括：

- 局部变量表：存放方法参数和方法内部定义的局部变量

- 操作数栈：压栈和出栈的过程

- 动态连接：每个栈帧都包含一个指向运行时常量池中该栈帧所属性方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。在 Class 文件的常量池中存有大量的 符号引用，字节码中的方法调用指令就以常量

  池中指向方法的符号引用为参数。这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接

  引用，这种转化 称为静态解析。另外一部分将在每一次的运行期期间转化为直接引用，这部分称为动态

  连接

- 方法返回地址：方法执行之后会有两个方式退出这个方法：正常退出和异常退出。方法正常退出，调用者pc计数器的值可以作为返回地址，栈帧中可能会保存这个计数器的值。异常退出，返回地址是通过异常处理器来确定的，栈帧中一般不会保存这部分的信息。


栈内存溢出SOF:

- 原因：栈帧压栈的时候，超出了栈的深度(方法递归)


##### 1、堆

类加载器读取类文件之后，需要把方法放入堆内存中

堆内存分为三部分：

- 年轻代：伊甸区8和幸存者区1:1（占1/3）
- 年老代：年轻代中被筛选出来的JAVA对象(占2/3)
- 持久代：用于存储静态文件，如java类、方法（在1.8之后就没有持久代了，由元空间取代来存储静态文件）


堆内存溢出OOM:

- 原因：超出了JVM堆设置的最大值

- 创建线程池超出了系统的限制


##### 1、简单参数调优

-Xms：设置初始分配大小。默认为物理内存的1/64

Xmx：设置最大内存分配

设定新生代大小：

- -XX:NewSize：新生代大小
- -XX:NewRatio：新生代和老年代占比
- -XX:SurvivorRatio:伊甸区和幸存者区的占比

设置垃圾回收器

- -XX:+UseParNewGC:年轻代
- -XX:+UseConcMarkSweepGC：老年代



-XX:+PrintGCDetails:输出详情的GC处理日志

-XX：+PrintCommandLineFlags -version：查看服务器中默认的垃圾回收器



##### 1、调优目录和调优工具

- jdk监控和故障处理命令有jps、jstat、jmap、jhat、jstack、jinfo
- 调优工具：jconsale、jvisualvm（自带全能工具，可以分析内存快照，线程快照。监控内存、gc变化）




##### 1、如何排查JVM问题

对于还在运行的环境：

- jmap工具来查看jvm中各个区域的使用情况
- jstack查看线程运行的环境
- jstat查看垃圾回收的情况。不能频繁的发生fullGC，可能对象有些大，年轻代的内存不足导致直接进入了老年代，从而频繁的发送fullgc

如果已经出现oom：

- 在生成的dump文件中加上-XX -HeapDumpOnOutOdMemoryError -XX HeapDumpPath
- 利用jvisualvm来分析dump文件
- 根据dump文件查找异常的对象的实例或异常的线程
- 根据再进行详细的分析和调试




##### 2、基本数据类型

int、short、byte、long、double、float、char、boolean



##### 2、Object常用方法

①getClass

②clone实现对象的浅拷贝

③toString

④equals 子类一般需要重写

⑤hashCode：hash值相等equals不一定相等。equals相等 hash值必须相等 

⑥wait



##### 2、static修饰符的用法

①可以修饰成员变量、类、方法、代码块 。不可修饰构造器

②被static修饰的类或者是成员变量，静态修饰的成员不能访问非静态修饰的成员



##### 2、String 的常用方法

length、indexOf、charAt、subString、trim、split、replace、getByte、toLowerCase、toUpperCase、isEmpty...



##### 3、面向对象的思想和特征

万物皆对象，对象拥有自己的属性和方法在程序中我们都需要创建对象进行一系列的操作。

特征：

①封装：把对象的属性和行为整合到一个整体，增加安全性

②继承：子类继承父类的属性和行为，在原有的类中建立新的技术

③多态：父类中定义的属性和行为被子类继承后，具有不同的表现行为

④抽象：不能被实例化，为继承而存在，对具体概念的抽象



##### 2、重载和重写的区别

①重载在发生在同一个类中，方法名必须相同 ，参数列表可以不同（顺序、个数、类型）

②重写是发生在父子类中，方法名和参数列表必须相同，范围大于父类



##### 3、==和equals的区别

①基本数据类型：==是比较值是否相同

②引用数据类型：==是比较对象的地址值是否相同，equals是比较地址值（默认），特殊情况：String、Integer、Date如果被equals重写，比较的就是内容



##### 4、hashcode和equals

①hashcode相同，对象不一定相同

②hashcode不同，对象一定不相同

③对象相同，hashcode一定相同



##### 4、String、StringBuffer、StringBuilder的区别

①String 被final修饰，相当于是一个字符串常量，线程安全。操作少量数据

②StringBuilder：没有加同步锁，线程不安全，在单线程下操作大量数据

③StringBuffer：对方法加入了同步锁或者是调用的方法加了同步锁，所以是线程安全的，在多线程下操作大量数据



##### 5、抽象类和接口的区别

①抽象类：子类使用extends继承，抽象类有构造函数、main方法，可以是任意修饰符

②接口：使用implements实现，没有构造函数、main方法，默认使用public修饰符

③类可以实现多个接口，但是只能继承一个抽象类



##### 6、并行、并发、串行

①并发：一个处理器处理多个任务

②并行：多个处理器处理多个不同的任务

③串行：一个任务执行完，才能执行下一个任务



##### 7、什么是单例模式

①单例模式：某个实例在多线程的环境下只会被创建一次

②单例三种模式：

- 饿汉式（一开始就初始化，只会创建一个实例，线程安全）
- 懒汉式（延迟初始化，可能同时处理多个请求创建多个实例，非线程安全）
- 双检索（线程安全，延迟初始化。两次非空判断：①验证是否创建对象（避免不必要的同步）②避免重复创建单例（多线程在第一次判断的时候可能在等待锁，从而创建新的对象的实例））





##### 7、浅拷贝和深拷贝

①浅拷贝只复制某个对象的指针，不复制对象本身，新旧对象共享到同一块内存

 ②深拷贝会创建另外一个一模一样的对象，新旧对象不共享内存，修改对象也不会影响到原对象



##### 7、零拷贝是什么

①应用程序在需要把内核中的一块区域数据转移到另外一块区域，不用复制直接转移

文件从磁盘中拿出来---->放到readBuffer---->读到ApplicationBuffer应用程序--->再把文件内容放在Socket buffer中

零拷贝流程：不需要读到applicationBuffer中，使用transferTo()，直接读取到socket buffer中再进行发出







##### 8、jdk8的新特性

①lambda表达式

②方法引用

③函数式接口（只包含一个抽象方法的接口）

④接口中存在一个或者多个非抽象方法和静态方法

⑤StreamAPI 

⑥时间类的改进LocalDate、LocalTime、LocalDateTime

⑦Option类

⑧Base64 编码和解码



##### 9、Java异常

①Throwable是所有异常类的父类，其中有error和exception

②Error：属于jvm的错误，是无法恢复的错误，会导致jvm无法运行

③Exception：

- 运行时异常，可以捕捉也可以不处理，其中有运行时异常(包含空指针异常、下标越界异常等)
- 非运行时异常，必须处理，不然编译不能通过（RIOException、ClassNotFoundException）




##### 9、什么时候抛出、捕获

主要判断这个异常自己能不能处理，如果能处理就捕获，如果不能处理就抛出给上层



##### 10、BIO、NIO、AIO区别

①BIO：同步阻塞式IO，传统的IO，处理并发的能力低

②NIO：同步非阻塞IO，传统IO的升级，客户端和服务端通过channel通道通讯，实现多路复用

③AIO：异步非阻塞IO，是NIO的升级，操作是基于事件的回调机制。某个channal已经将客户端发来的消息读取完毕，再进行通知



## 锁

##### 11、同步锁、死锁、乐观锁、悲观锁

①同步锁：当多个线程访问一个数据时，很容易出现问题，为了避免这个问题，保证线程的同步互斥，可以加一个同步锁

②死锁：当多个线程访问一个数据时发生了堵塞，都在等待资源被释放

③乐观锁：当别人去拿数据时 都认为不会被修改，所以不会上锁，但是在此期间会判断数据是否被修改（多读），cas算法：读A，修改A为B之前，查看A是否被修改  那如何判断是否被修改：这时候存在一个ABA问题，使用版本号机制version字段+1进行操作（可能导致cpu飙高）

④悲观锁：当别人 去拿数据时都认为会被修改，所以会上锁会堵塞，直到拿到这个锁。其中ReentrantLock是典型的悲观锁



##### 11、怎么避免死锁

①互斥，当资源被一个线程抢占时，别的线程不能使用

②不可抢占：资源请求者不能强制从资源占有者手中夺取资源

③请求和保持：资源请求者在请求资源时同时保持对原有资源的占有

④循环等待：p1占有p2的资源、p2占有p3的资源、p3占有p1的资源，线程一个等待环路



##### ***11、锁分类

###### ①乐观和悲观锁

- 乐观锁：java并发包下的Atomic原子类，多读场景
- 悲观锁：ReenTrantLock等独占锁，多写场景



###### ②公平锁和非公平锁

- 公平锁：就是比较公平，根据锁的顺序排列，先请求先到先得锁。（队列存放--链表）---AQS

- 非公平锁：根据cpu的抢占来决定先后顺序  效率非公平锁>公平锁


###### ③自旋和重入

- 重入：在同一个过程中锁可以不断传递，可以直接获取

- 自旋（CAS自旋锁）：通过循环控制一直不断的获取锁，没有获得锁的线程是不会阻塞的。避免线程之间频繁的阻塞和唤醒


###### ④synchronized偏向锁、轻量级、重量级

无锁标志位 01  

对象内存：

1. 对象头（存放markword8和class point 8 ）
2. 实例变量（对象的实例信息）
3. 填充字节（因为虚拟机的字段必须为8字节的整数倍，凑数）



- 偏向锁01：在锁对象的对象头中记录线程id，下次这个线程可以直接获取锁

  适合1个线程，可以减少不必要的CAS操作


- 轻量级锁00（markword存储的是指向线程栈中的Lock Record指针）：

  另外一个线程想来竞争这把锁，这个时候偏向锁就会升级为轻量级锁（原来持有的偏向锁的线程到达安全点：当前没有字节码执行）

  适合少个线程，本质就是CAS自旋锁，都是运行状态

  线程B在争抢时发现markword中的线程ID不是线程B而是线程A时，线程B就会进行cas操作


  （所有的java对象都带锁，因为java对象携带monitor   count：记录被线程获取锁的次数。 recursions：锁重入的次数、owner：资源对象的线程、waitset、waitSetLock、EntryList）

- 重量级锁10（指向堆中的monitor对象的指针）：

  自旋次数过多就会升级到重量级锁

  适合多个线程，只有一个执行，其他的线程挂起

  基于进入和退出monitor对象实现，在编译时会将同步块的开始位置插入monitor enter指令。结束插入monitor exit指令

  monitor enter指令：拿到了重量级锁，会在monitor的owner中存放当前线程id


  锁升级是为了提高获取锁和释放锁的速率




java利用synchronized实现同步

- 普通方法，锁是当前的实例
- 静态同步方法，锁是当前的class对象
- 同步代码块，锁是synchronized括号里配置的对象

synchronized修饰的同步语句块使用的是monitor enter、monitor exit指令

synchronized修饰的方法是ACC_SYNCHRONZIED标识，该标识指明了该对象的同步方法（这两种的本质都是通过monitor获取）







⑤独占锁和共享锁（AQS实现）

- 独占锁：也叫排他锁，只允许一个线程获取锁。
- 共享锁：多个线程可以同时持有锁，加了共享锁就不能加排它锁。获得了共享锁只能读，不能修改数据。






##### 11、CAS自旋锁

compareAndSwap比较并替换

- 有三个操作数：V内存值、A旧的预期值、N修改值
- 原理：A  == v，才能修改N
- 优点：没有获得锁的线程是不会阻塞的，通过循环控制一直不断的获取锁
- 缺点：通过死循环控制，消耗cpu资源较高，需要控制次数，避免cpu飙高问题




##### 11、ThreadLocal原理

ThreadLocal提供给我们每个线程缓存局部变量，线程隔离。

①每个线程都有自己独立的ThreadLocalMap对象（使用entry对象进行封装）

②如果当前线程对应的map对象为空，则创建

③key为当前 ThreadLocal对象，value为变量副本

④在不使用线程池的情况下，不调用remove方法，线程的副本也会被垃圾回收，不会造成内存泄露的问题



②set方法：

- 获取当前的主线程，获取主线程中的ThreadLocalMap对象
- 判断map是否为空。如果不为空：设置key=当前ThreadLocal对象  value=局部变量值（线程副本）。如果为空就创建

④get方法：

- 获取当前的主线程，获取主线程中的ThreadLocalMap对象
- 再获取相应的ThreadLocal值





##### 11、ThreadLocal应用场景

①Spring事务模板类（提供共同骨架，具体交给子类实现）

②在SpringMVC中获取httprequest对象

③在控制层将变量缓存到ThreadLocal中-----业务逻辑层获取ThreadLocal获取到该变量



##### 11、如何预防ThreadLocal内存泄露问题

①key是使用弱引用，容易被gc垃圾回收

②key被回收，但是value还在。所有就会导致内存泄露

解决：

- 每次使用完都调用remove()方法，清除数据
- 每次set的时候都会清除之前的key=null




为什么key不是强引用：

将threadLocal的引用指向null，ThreadLocal的key因为是强引用不会被gc回收，会出现内存泄露问题




##### 12、synchronized原理

可以保证方法或者是代码块在运行的时候，同一时刻只能有一个方法进行临界区，同时还可以保证共享变量的可见性

用法：

①静态方法上，锁是当前类的Class对象

②作用在普通方法上，则锁是当前的实例（this）

③作用在代码块上，在执行完或者出现异常时自动释放锁

原理：

①底层是采用java对象头来存储锁信息的，并且还支持锁升级

②在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步



##### 13、volatile内存可见性过程

①线程写volatile的过程：

- 改变线程本地内存中volatile变量副本的值------>从本地内存刷新到主内存

②读过程：

- 从主内存中读取volatile变量的最新值到本地内存中------>从本地内存读取volatile变量的副本



##### 13、volatile内存可见性原理

①写操作：

通过写指令加入一条store屏障指令，让本地内存变量的值刷新到主内存中

②读操作：

通过读指令前加入一条load屏障指令，及时读取变量到主内存的值



屏障指令：cpu指令，控制重排序和内存可见性



##### 13、volatile编译器内存屏障

- 写写屏障可以保证在volatile写之前，在前面的操作都已经刷新到主内存中
- 写读屏障避免操作重排序
- 读读屏障禁止处理器把上面的volatile读与下面的普通读重排序
- 读写屏障禁止处理器把上面的volatile读与下面的普通写重排序





##### 13、volatile原子性问题解决

①使用synchronized

②使用reentrantLock可重入锁

③使用AtomicInteger原子操作



##### 14、volatile适用场景

①独立于其他变量

②使用boolean变量



##### 13、synchronized和volatile区别

volatile：

- 本质是告诉jvm当前变量在寄存器中的值是可变的，需要从主存中读取
- 是变量级别。轻量级
- 保证可见性，有序性。但是不能保证原子性（并发操作下要么全部成功要么全部失败）
- 不加锁，所以不会造成线程阻塞
- 被volatile标记的变量不会被编译器优化

synchronize

- 是锁定当前变量，只能有一个变量进入临界区，其他的线程进入堵塞的状态
- 可以使用在变量、方法、类级别。重量级
- 保证可见性、原子性
- 可能会造成线程阻塞
- 被synchronize标记的遍历会被编译器优化




##### 14、synchronized和Lock的区别

|     sychronized      |                 Lock                 |
| :------------------: | :----------------------------------: |
|         关键字          |         接口（实现类ReentrantLock）         |
|        自动释放锁         |       需要在finally中手动释放锁(unlock)       |
| 线程1阻塞 线程2会一直等待（不可中断） | 线程不需要一直等，tryLock方法尝试获取锁（可中断也可以是不可中断） |
|         非公平          |                公平、非公平                |
|                      |         int类型的stat标识锁状态：0无锁          |



##### 11、Lock锁实现原理

AQS+CAS+LockSupport



CAS；

compareAndSwap比较并替换

- 有三个值：V内存地址、A旧的预期值、N修改值
- 原理：A（当旧的预期值）  == v（共享变量值），才能修改N
- 优点：没有获得锁的线程是不会阻塞的，通过循环控制一直不断的获取锁
- 缺点：通过死循环控制，消耗cpu资源较高，需要控制次数，避免cpu飙高问题



LockSupport：

- part():阻塞当前线程
- unpart()；唤醒当前阻塞线程







##### 11、AQS

①队列同步器，来构建锁、同步器的基础框架。lock实现类都是基于AQS实现

②获取一个共享资源，然后利用队列让线程排队获取资源的过程

③在AQS中维护了一个信号量state和一个线程组成的双向链表队列。通过state记录加锁的次数 加锁+1   释放锁就-1



## 集合：

##### 15、数组和集合的区别

①数组是定长的，只能存放一种数据类型

②集合可以动态扩容，存放的类型可以不是一种



##### 15、常见的缓存淘汰算法

①FIFO先进先出

②LRU使用时间最远（recently）

③LFU使用次数最少（frequently）



##### 15、List、Set、Map

①set和list是单列的，map是双列的集合

②List是有顺序的（允许重复）

- arrayList（底层是数组，查询快增删慢）chi

扩容机制：原始长度为0，初始长度10，扩容时原来*1.5

- LinkedList  （链表，查询慢增删块） 
- vector效率低 已经被舍弃

②Set是无序的（去重）

- HashSet（hash表，通过重写equals和hashCode方法来保证唯一）
- TreeSet（红黑树，排序：自然排序和比较器排序）
- LinkedHashSet（链表和hash表，有序唯一）

③map的键是不允许重复的，值是允许重复的

- hashMap（线程不安全，允许有null值）-------子类LinkedHashMap插入有序，线程不安全
- hashTable（线程安全Synchronize，不允许有null值）
- TreeMap（键值升序排序，线程不安全）







##### 16、&和&&

①共同点：两者都是逻辑与运算符，两者为true才为true

②不同点：&是按位与，两边都是boolean的时候，就会执行操作。&&是短路与，如果左边为false时另外一个就不会判断



##### 17、ArrayList和LinkedList区别

①ArrayList：底层是动态数组，查询快 增删慢，线程不安全

②LinkedList：底层是链表，查询慢 增删快，线程不安全



##### 18、hashMap的底层原理

①在jdk1.7之前使用的是数组+链表（头插法），1.8之后使用的是数组+链表+红黑树（尾插法）

②当我们调用put方法添加的时候，才会去创建一个默认长度16 加载因子为0.75的数组。数组长度>64且链表长度>8时会自动转换为红黑树，当链表长度<=6时退化为链表。（转换）

③当我们存储的元素个数>=默认长度16*0.75=12时会进行第一次扩容，扩容长度为初始长度的一倍 32（扩容）

④new hashMap的时候传进去的值不是值2^n的时候，会自动把数字的长度变为2^n（保证翻译成二进制之后只保证有一个byte位）

  实际上是通过 数组下标计算：通过hash值和长度的与运算（hash &(length-1)），按位与运算：减少hash冲突（数组下标计算）

⑤put方法：首先调用hashcode方法，获取存储元素的hash值，然后计算数组下标得到我们存放数组元素的下标索引位置，再调用equals方法，比较元素的内容查看是否一致，一致替换，不一致调用put方法将元素存入。（hash值不同，对象一定不同。hash相同，对象不一定相同）

⑥get方法：计算hash值，通过hash值计算数组下标快速定位，如果没有元素返回null（如果位置上有单向链表：就与单项链表中的每个节点进行对比，所有equals方法返回false，则get方法返回null），如果在某个节点中的equals返回true，那么get就是需要返回这个value



为什么允许有null值：当key== null返回的值为0，hash算法返回为0，不会调用key的hashcode方法



两个对象hashcode相等，值不一定相等。如果对象的值相等，hashcode一定相等。



key查询时的时间复杂度：

1. key没有hash冲突，O(1)
2. key有hash冲突，采用链表存放O(N)
3. hash冲突采用红黑树，O(LogN)



hashmap底层是有序的吗：无序，因为hash算法是散列计算。如果需要有序采用linkedHashMap



1.7死循环问题：hashmap本来就是线程不安全的，是不推荐在多线程的环境下使用。采用头插法在并发情况下会导致死循环。





##### 18、hash冲突

不同对象计算出来的数组下标可能会相同，就可能会产生hash冲突，当不同hash值的key落在同一个位置时就会形成单项链表，当单向链表达到一定长度的时候效率会非常低，所以大于8时链表会转换为红黑树，提高查询的效率



##### 18、解决hash冲突

①再hash法：使用另外一个hash来进行计算

②开放寻址法：在冲突的位置寻找一个数组下标

③建立公共的溢出区：将冲突的key放在公共的移除区

④链地址法：



##### 19、hashMap、hashTable、ConcurrentHashMap

hashmap：线程不安全的。允许有null值，适用于单线程

hashtable：线程安全的，不允许有null值，适用于多线程

但是没必要因为多线程的情况去使用hashtable，因为hashtable内部有内部同步锁，从而是低效的。

可以使用concurrentHashMap替代。



##### 19、ConcurrentHashMap底层原理

②1.7采用了segment分段锁，一个线程操作一个segment，将大的hashmap分成多个小的hashTable，从而实现多线程。但是多线程同时put操作key方式了index冲突落到同一个hashtable上还是会产生锁的竞争

③1.8之后是使用CAS+sysnchronized来保证线程的安全，结构与hashmap相似，底层数据结构数组+链表+红黑树



为什么不允许key为null：

- 为了避免多线程并发环境下出现线程安全问题。
- 一个线程获取key，返回结果为null，这个时候线程是无法确认的
- 如果null表示的是不存在key、还是存在这个key呢 这种不确定性会造成线程安全问题



## 线程：

##### 19、线程安全的理解

我们写的某一段代码，在多线程的同时操作下，会不会产生正确的结果



##### 19、线程安全的集合类

①hashTable、vector、concurrentHashMap

②Collections工具类，将非线程安全的集合封装成线程安全的类中





##### 20、进程和线程的区别

①进程：正在运行程序的实例，一个进程包含一个或多个线程

②线程：进程在执行过程中基本单位



##### 20、进程、线程分别的通信方式

进程：管道、信号量、消息队列、共享内存

线程：如果使用了同步锁，采用wait、notify、notifyAll。如果使用的是lock。则采用await、singal、singalAll、消息队列



##### 21、创建多线程的方法

①继承Thread类（不能继承其他类）

②实现Runnable、callable接口

③创建 线程池



##### 22、Runnable和Callable的区别

①Runnable：实现run方法没有返回值，只能抛出运行时异常，不能捕获异常

②Callable：实现call方法，支持泛型，可以捕获异常，允许抛出异常



##### 23、线程中start和run的区别

①run方法，是thread类中的基本方法，封装多线程的代码，直接使用，并没有开启线程

②start方法：由jvm调用run方法，开启线程，使线程进入就绪的状态



##### 24、线程有几种状态

①创建状态，生成线程对象

②就绪状态，线程对象调用start方法，进入就绪状态，但是还未把当前线程设置为主线程

③运行状态，设置当前线程为主线程，开启run方法里面的代码

④阻塞状态，1、等待wait   2、超时等待sleep   3、同步阻塞synchronized

⑤死亡状态，退出run方法，结束生命周期



##### 25、线程相关的基本方法

①线程等待wait  ，需要notify、notifyAll来唤醒

②线程让步yield，当前线程让出cpu的执行权

③线程中断interrupt，中断一个线程

④join等待其他线程终止



##### 26、保证线程安全的几个基本特性

①原子性：操作不会被其他线程干扰

②可见性：一个线程修改了某个变量，状态是可以被另外的线程知晓

③有序性：禁止指令重排序



##### 26、wait和sleep的区别

①wait是属于Object类、sleep是属于Thread类

②wait会释放锁，sleep不会释放锁

③wait使用在同步代码块中，sleep使用在任何地方

④wait不需要捕获异常，sleep需要捕获异常





## 线程池

##### 28、为什么使用线程池(作用)

①频繁的开启线程或者是结束线程，线程需要重新被cpu从就绪到运行，上下频繁切换

②线程复用（提前准备好一些固定的线程数一直在运行状态，提高响应速度）

③统一维护和管理

④可以做定时线程池



##### 28、项目中哪用到了线程池

①开发中禁止自己new线程。必须使用线程池来维护和创建线程

②如果异步的去发短信，就会使用到线程池。如果项目比较大一般是使用mq做异步



##### 28、线程池的创建方式

Executors有6个API：不推荐使用  原因：传的是一个无界的队列缓存（Integer.max_value），可能出现溢出问题

①newCachedThreadPool：可缓存线程池

②newFixedThreadPool:可定长度 

③newScheduledThreadPool：可定时

④newSingleThreadExcetor：单例的线程池

⑤newSingleThreadScheduledPool：单例定时线程池

⑥newWorkStealingPool：带并行级别的线程池

底层都是使用ThreadPoolExecutor来封装





##### 28、线程池如何做到复用

①提前将线程固定的线程设置为运行状态（死循环）

②提交的线程任务缓存到并发队列集合中





##### 28、线程池的核心线程数

①线程池大小corePoolSize

②最大线程数maximunPoolSize

③存活时间KeepAliveSize

④存活时间的单位init

⑤阻塞队列workQueu

⑥创建线程工厂threadFactory

⑦拒绝策略handler





##### 29、线程池的原理

①提交者提交任务，查看线程池是否已满，如果没满创建线程，如果满了进入阻塞队列

②查看阻塞队列是否已满，如果没满将任务存储在队列 中，如果满了进入线程池

③查看线程池是否已满，如果没满创建线程执行任务，如果满了按照饱和策略处理





##### 30、饱和策略的四种方式

①AbortPolicy：丢弃任务并抛出异常

②DiscardPolicy：直接丢弃任务

③DishcardOldestPolicy：丢弃队列中最前面的任务

④CallerRunsPolicy：既不抛弃任务也不抛出异常

实现rejectedExcecutionHandler接口，自定义异常处理器，可以将多余的线程保存到本地





#### ---------GC垃圾

##### 32、GC垃圾回收

私有的线程不会产生垃圾，只有共享线程会产生垃圾，存在于堆内存中

①怎么找到垃圾：

1. 根可达算法：GC  Root根节点出发，寻找对应的引用节点，向下去进行搜索，对象无法到达CG ROOTs的就判定为垃圾对象。

   java中可以作为GC  ROOTs（枚举根节点）结点的对象有
   1.虚拟机栈中的引用对象（栈帧）
   2.本地方法栈中的引用对象
   3.方法区中静态属性引用的对象
   4.方法区中常量引用的对象

2. 引用计数法（jdk1.1使用）：被引用一次+1，减少一次引用-1，直到为0 就是垃圾（缺点：两个对象相互引用，可能出现循环依赖）

②怎么回收垃圾：

1. 标记清除法

   标记出来需要回收的对象，标记完成之后统一回收被标记的对象

2. 标记整理法（效率低）

   标记之后，让所有存活的对象向一端移动，在移动的过程中清理掉清理掉可以回收的对象

3. 复制算法（不会产生内存碎片）

   把空间分为两块，当一块已经满了的时候，复制到另外一块中，并排列好 全部删除

4. 分代收集法

   根据对象的存活周期来划分，不同生命周期采用不同算法

③垃圾回收的过程：

1. 所有新生的对象都会放在年轻代中（年轻代：eden区、survivor0区、survivor1区）
2. eden区将对象复制到survivor0区，然后清空eden区。当survivor0区放满的时候，将eden、survivor0存活的对象复制到survivor1区，清空eden、survivor0区。
3. 然后survivor1和survivor0区往复交换，survivor1满的时候，会将存活的对象放到老年区
4. 若老年区也满了，就会触发Full GC，将年轻代和年老代全部回收




垃圾回收为什么要进入STW

- 没有STW会出现一些浮动的垃圾，回收性能差，通过快照将时间冻结到某一个时间点

如何减少STW

- 合理分配内存，减少full GC
- 选择更优的GC收集器减少停顿时间





##### 33、强引用、软引用、弱引用、虚引用

①强引用：就算造成oom，也不会被该对象进行回收

②软引用：内存充足不回收，内存不足回收

③弱引用：不管当前内存是否足够，都会被回收

④虚引用：就跟没有任何引用一样，并不会决定对象的生命周期





##### 33、垃圾回收器

①新生代收集器：serial、parnew、parallel  scavage

- serial：单线程收集器，在进行垃圾回收的过程中，必须暂停其他线程的工作，stw

-XX:+UseSerialGC开启之后会使用serial+serialOld收集器组合

- parnew：多线程收集器，parnew+CMS+SerialOld
- parallel scavage：吞吐量优先收集器，高效利用cpu时间。吞吐量=（程序运行时间）/（程序运行时间+垃圾回收时间）

②老年代收集器：serialOld、parallel old、CMS

- serialOld已经不用了，主要用于辅助。防止parallelOld CMS挂掉
- parallel old多线程，无法提供整体的吞吐量
- CMS：回收时间短，适合堆内存大的服务端应用 优点：并发、停顿低  缺点：造成cpu资源压力大

③混合收集器：G1

- G1的目的就是取代CMS。有整理过程的垃圾回收器，不会产生内存的碎片化
- G1的STW是可控制的，添加预测机制，用户可以指定预期停顿时间
- G1变成了一个个大小一致的region（1-32M）.整堆默认2048  32*2048=64G




G1原理

- 按照区域进行扫描，整体为不连续的内存区域，不要求物理连续只需要逻辑连续
- 每个区域也没有年轻代和老年代的划分，可以相互切换
- XX:G1HeapRegionSize=n



G1回收过程：

- 初始标记：只标记CG ROOT能直接关联的对象
- 并发标记：进行CG Tracing的过程
- 最终标记：修正并发标记期间，导致标记变化的一部分对象
- 筛选回收：根据时间来进行价值最大化的回收





④整堆收集：

serial+serial old客户端垃圾收集器

parnew+CMS+SerialOld服务端垃圾回收

parallel scavage+parallelOld

parallel scavage+Serial old



堆内存溢出优化：

增大堆内存set JAVA_OPTS=-server -Xms512m -Xmx1024m -XX:MaxNewSize=1024m -

XX:MaxPermSize=1024m



守护线程：jvm后台的线程，如果其他线程全部关闭，守护线程才会自动关闭







## 网络

##### 33、TCP和UDP的区别

①TCP:可靠、面向连接、少量数据、传输慢

②UDP：不可靠、面向无连接、大量数据、传输快



##### 34、OSI七层模型

物理层--数据链路层--网络层--传输层--会话层--表示层--应用层



##### 35、三次握手、四次挥手

①三次握手：（建立可靠的通信）

1. 服务端向客户端发送syn包 连接请求，查看是否可以建立连接
2. 同意连接发送syn+ack包
3. 收到回复ack包，建立连接 

②四次挥手：（保证传递数据不丢失）

1. 客户端向服务端发送fin包，表示关闭连接
2. 服务端发送ack包表示已经进入了关闭状态
3. 服务端再次发送fin包确认
4. 客户端收到后回复ack包给服务端




##### 36、http和https的区别

①端口号不同：http80，https443

②https在传输的过程中会消耗cpu和内存资源

③https通信需要证书，这类证书需要去申请或者是付费购买





#### ------JavaWeb

##### 36、转发和重定向的区别

转发：request.getRequestDispather().forword()

重定向：response.sendRedirect()

①重定向   2次    请求、转发        1次    请求

②重定向  地址栏 会变、转发       不会

③重定向  浏览器  跳转、转发    服务器    跳转

④重定向 任意网站、请求转发只能跳转到当前项目



##### 37、get和post区别

①get请求在传输数据的过程中，请求是放在url中，是不安全的。post是不可见的，安全。

②get传输数据2-4k，post无限制

③get字符集必须为ascii字符集，post支持整个ISO10646字符

④get效率比post好，get为默认的提交方式



##### 38、cookie和session的区别

①cookie存在于客户端，session存在于服务端

②cookie保存数据大小<=4kb，一个站点最多存储20个cookie。session无限制

③cookie只存储ASCII字符集，session存储任意字符集

④cookie对客户端可见，不安全。session存在于服务器，不存在信息泄露的风险

⑤可以设置cookie的有效时长。关闭窗口session就会失效

⑥cookie存在于客户端，不占用服务端的资源，可以减少服务端的压力。每个用户都会产生一个session，并发高时很耗内存



##### 39、什么是Ajax

①Ajax是异步的javaScript和xml

②不需要加载整个页面，就能更新部分网页技术

③异步的可以提高用户的体验，减少不必要的数据往返，存在于客户端，减少了服务端的负担



##### 40、Linux常用命令

-ll：查看指定目录下的内容

cd..:上一级目录

cd~:切换到home目录

cat -n /etc/profie：查看比较小文件内容

more fileName：查看日志内容

 

tail：查看文件末尾内容（用于日志文件的内容输出）

taile /etc/profile:显示最后10行内容

taile -20  /etc/profile:显示最后20行内容

taile -f xx.txt:动态打印内容



mkdir xx：创建目录

mkdir -p 1/2/3:创建多层目录

rmdir：删除目录 

rm -rf/*:删除所有



cp xx.txt 指定目录：复制xx.txt到指定目录

cp xx.txt ./hi.txt:复制到当前目录下。并改名为hi.txt

ps -ef |grep ：显示进程信息

kill -9 线程号：杀死线程



mv xx.txt hi.txt:将xx.txt改名为hi.txt

mv xx.txt itheima/：将xx.txt 一定到itheima目录下

mv xx.txt itheima/hi.txt:将xx移动到itheima目录中改名为hi

mv itcast/ itheima/:不存在则改名，存在就移动到itheima目录下



tar -cvf test.var test:把test目录进行打包

tar -zcvf test.tar.gz test：打包＋压缩

tar -xvf test.tar：解包test.tar到当前目录

tar -zxvf test.tar.gz -C /user/local：解包test.tar到指定目录





vi/vim文本编辑工具

yum install vim:安装vim



find .  -name"*.java"查找以java结尾的文件

grep hello hello.java:从java文件中查找hello.java



systemctl start/status：查看服务状态



##### 42、I/O多路复用

①单个进程或者是线程同时处理多个IO请求

②select、epoll、poll是LinuxApi提供的复用方式

③select是将装有文件描述符合的集合从用户空间拷贝到内核空间（数组 有上限）

④poll底层是链表，没有上限

⑤epoll是回调的形式，底层是红黑树，避免轮询





##### 43、JWT

- 进行身份验证
- 实际上就是一个字符串，三部分组成：头部、载荷、签名
- 头部：算法    载荷：里面有一个jti唯一的身份标识，主要用来作为一次性token  签名：header、payload、secret




cookie、session的弊端

- 不支持跨域访问。token将请求放在请求头中，支持跨域访问

- session需要存储服务端，通过cookie中的sessionID在服务端找到对应的session

- session存放在服务端中，当我们在并发高的场景下，会占用服务端大量的资源

- cookie用户识别，如果cookie被获取，用户就很容易收到cookie欺骗的攻击

- 防止csrf攻击，token更适合restful风格

- 前后端分离最好使用token。因为session+cookie是基于web。更适合移动端，因为移动端不支持cookie


##### 44、token

**什么是token：

- token是服务端生成的一串字符串，作为向客户端请求的一个令牌
- 开销小、支持跨域、身份验证
- 特点：随机性、时效性、防止csrf攻击、无状态



**流程：

1. 客户端发送用户和密码请求登录
2. 服务端收到请求，验证用户名和密码
3. 验证成功后，服务端会向客户端发送一个token（生成token）
4. 客户端收到token进行储存在cookie或Local Storage
5. 客户端每次向服务端请求资源的时候都携带token
6. 服务端收到请求，会去验证请求里面携带的token。验证成功向客户端返回请求数据

前端一旦收到token的异常码，就会删除本地存储的token



**token有效期

- token可以自定义时长，时间设置短用户频繁登录，设置长会不太安全

- 考虑双 token

  正常请求后端服务时，携带access_token，如果access_token失效就通过refresh_token到后台服务器中获取新的access_token和refresh_token，实现token的续签。直到refresh_token过期，需要用户重写登录



**双token：

- 用户登录成功后，生成两个token，分别是access_token（5分钟）、refresh_token（24小时，存到redis中）
- 将access_token、refresh_token给前端。前端接收到的数据接口携带access_token进行11第一次校验
- 如果校验token失败，响应401
- 然后刷新token，携带refresh_token进行11第二次校验。如果token无效，重新登录，如果token有效，就从redis中查询11是否已经使用。如果token有效就重新生成access_token和refresh_token
- 删除旧的refresh_token，储存新的refreh_token到redis。返回新的两个token到前端。



##### 44、Tomcat为什么要使用自定义类加载器

如果两个服务的名字是一样的，需要共用一个类，就需要自定义类加载器

进行隔离，不冲突



##### 45、单例bean和单例模式

①单例模式

②单例bean：在spring容器中获取bean的时候，根据相同名称获取同一个bean对象



##### 46、浏览器发出一个请求到收到响应经历了什么

①浏览器解析用户输入的url，生成一个http格式的请求

②先根据url域名从本地的host文件查找是否有映射ip，如果没有就发送给用户配置的dns解析解析，得到ip

③浏览器通过操作系统将请求通过四层请求发出去，途中可能经过交换机、路由器等。最终到达服务器

④解析端口，将请求传递给绑定该端口的应用程序

⑤tomcat会接收这个请求，按照http协议的格式进行解析，得到访问的servlet

⑥然后servlet来访问这个请求，如果是springmvc中的dispacherServlet，那么则会找到对应的controller中的方法，并执行这个方法所得到的结果

⑦tomcat得到对应的响应结果之后，封装成http响应的格式，并再次通过网络发送到浏览器所在的服务器

⑧浏览器所在的服务器拿到结果后再把结果给浏览器，浏览器负责解析和渲染



##### 47、拦截器和过滤器的区别

原理实现上：过滤器基于回调实现，而拦截器基于动态代理。

控制粒度上：都能够实现对请求的拦截功能，拦截器对访问控制的粒度更细。

使用场景上：拦截器往往用于权限检查、日志记录等，过滤器主要用于过滤请求中无效参数，安全校验。

依赖容器上：过滤器依赖于Servlet容器，局限于web，而拦截器依赖于Spring框架，能够使用Spring框架的资源，不仅限于web。

触发时机上：过滤器在Servlet前后执行，拦截器在handler前后执行，现在大多数web应用基于Spring，拦截器更细。



48、阻塞队列

塞队列常用于生产者和消费者的问题中，比如volatile、CAS、AtomicInteger。

阻塞队列和普通对列区别：
1.当阻塞队列为空的时候,不允许获取元素
2.当阻塞队列为满的时候,不允许添加元素

引入阻塞队列以前,要自己去阻塞线程,唤醒线程,有了阻塞队列之后，都给我们做好了

常见的阻塞队列
1.ArrayBlockingQueue:数组结构的有界阻塞队列
2.LinkedBlockingQueue:链表结构的有界阻塞队列
3.SynchronousQueue:不存储元素的阻塞队列，只存一个元素




# 数据库



##### 1、左连接、右连接

①左连接：以左表为基准来进行查询，显示左表的所有数据，右表的数据如果与左表匹配，数据则会显示相应字段，如果不匹配则显示为null

②右连接：以右表为基准来进行查询，显示右表的所有内容，左表如果匹配则显示，不匹配显示null



##### 2、聚合函数

count、avg、sum、max、min



##### 3、sql语句执行顺序

from---where---group by分组--order by排序



##### 4、数据库的三范式

①1NF：原子性（列和字段不可再分解）

②2NF：唯一性（一张表只说明一件事情）消除部分依赖

③3NF：直接性（数据不存在传递关系，每个属性和主键都存在直接关系）消除间接依赖



##### 5、存储引擎myisam、innodb

①在mysql5.5之前是使用的myisam存储引擎，查询索引id的data值，根据data值查询文件对应的数据（非聚簇索引）

，支持表级锁。不支持事务和外键。磁盘上存储了三个文件：.frm（存储表定义）  .myd（存储数据）  .myi（存储索引）

查询过程：先查索引---->查数据---->数据文件



②5.5之后使用的是inodb存储引擎，支持事务和行级锁，支持聚集索引存储的方式（聚集索引：索引和数据存储到一张表中，一一对应的关系）

主动创建索引 

- 默认主键索引
- 没有指定，会使用mysql自带的rowid为主键

查询过程：查询数据直接找到数据文件



InnoDB为什么必须要有主键并设置自增

- 不建议uuid作为主键，不支持范围查询
- b+数底层搜索的时候可能会发生值比较判断



##### 6、事务的特性

①原子性：要么全干，要么全不干

②一致性：事务执行从一种正确的状态到另外一种正确的状态

③隔离性：一个事务执行的时候，不会被其他事务干扰

④持久性：事务提交之后，数据回会永久保存到数据库中



##### 7、事务隔离级别

①read-uncommited 读未提交（脏读）：读了未提交的数据，如果回滚就会出错

②read-commited读已提交（不可重复读和虚读）：读了已经提交的数据，如果再次修改会导致数据不一致

③repeatable-read重复读（幻读）：对事物进行增加或删除时，会导致数据不一致（mysql默认）

④serializable：效率低，最高隔离级别 少用



##### 7、mvcc多版本并发控制

①解决了幻读问题，解决读写冲突

②主要实现是三个隐藏字段、undolog、read view

③隐藏字段是：

- DB_TRX_ID:6个字节，最近一次修改事务的id
- DB_ROLL_PTR:7个字节，回滚指针，指向上一个旧版本
- DB_ROW_ID：6个字节，隐藏主键，如果没有主键就自动生成6个字节的row_id

④undolog：记录日志的回滚（历史版本）

⑤read view：并发时能否读到事务。包含三个全局属性

- trx_list:生成正在活跃的事务id数组
- up_limit_id:记录trx_list中最小的id
- low_limit_id:尚未分配的id

⑥比较规则：

- DB_TRX_ID(最后一次修改的id)<up_limit_id(list中最小的id)-----》可以看到DB_TRX_ID所在的记录
- DB_TRX_ID(最后一次修改的id)>=low_limit_id-----》不可见
- 判断DB_TRX_ID是否在活跃列表-------》尚未commit ，当前事务看不到
- 不在活跃列表的话，说明已经commit，修改的结果能够看见





##### 8、索引

1. 存储位置：索引存储在：磁盘，查询数据的时候 会将索引加载到内存中

2. 存储索引需要的信息：①key值：数据库中每一行存储的值 ②文件地址③offset偏移量

3. 索引用到的数据结构：b+树


4. 聚簇索引和非聚簇索引

   ①聚簇索引：将数据存储与索引放在一块，索引结构的叶子节点保存了行数据(物理有序)

   一个表只有一个聚簇索引，其他都是非聚簇索引

   ②非聚簇索引：将数据和索引分开，索引结构的叶子节点指向了数据对应的位置(物理有序，逻辑无序)


5. 回表：普通索引查询到聚簇索引的key之后，再根据key值在聚簇索引中获取行记录

   查询的索引树上，找不到当前内容，需要在另外的索引树上查询数据（覆盖索引）

6. 索引覆盖：当我们查询的内容与索引中的字段相对应，就不需要回表，当前字段在索引的叶子节点里面已经存在，可以直接作为结果返回


7. 联合索引：包含多个索引列


8. 最左匹配：遇到范围查询<> 后面的字段会停止匹配，>=  <=  between like不会停止匹配




##### 8、索引的分类

物理层面：聚簇索引和非聚簇索引

应用层面：

①普通索引：没有限制

②唯一索引：索引列的值必须唯一，允许空值

③主键索引：特殊的唯一索引，使用primary key 来约束 不允许有空值

④联合索引：最左前缀法（提高mysql效率）

⑤全文索引：针对较大的数据，耗时耗空间





##### 8、b+树

b树：

①key值和data值放在每一个节点，有上千个子节点，每个子节点中存放的是索引和数据 



b+树：

①非叶子节点只存储key值信息，data值都存在于叶子节点中

②叶子节点中存在链指针

③每个数据记录的节点都是按照键值的大小顺序存放在同一层的叶子节点上，增加了key值存储的数量，降低树的高度



优点：

①减少磁盘IO的次数，每个节点能索引的范围更大更精确，大量数据快速定位



##### 8、数据库为什么不用红黑树而用b+树

①索引的数据结构会被存储到磁盘中，每次查询都需要到磁盘中访问

②红黑树的树的高度可能会很高，进行多次读写的时候会进行多次的磁盘读写

③b+树的高度一般为2-4，最坏的情况也是进行4次磁盘的读写，在实际中性能是很不错的



##### 8、B+树索引和hash索引的明显区别

1、hash索引无法支持范围查询，因为原先是有序的键值，但是经过hash算法后，有可能变成不连续的，就没有办法利用索引完成范围查询检索数据。

2、hash索引也不支持多列联合索引的最左前缀匹配规则。

3、B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键的情况下，hash索引的效率也是极低的，因为存在hash碰撞问题。

4做单数据查询的时候哈希索引的速度快一些 因为它的时间复杂度最多为log(1) 而我们b+ 树索引是log(n)



##### 8、为什么b+树不适合全文索引

①文字字段一般是比较长的，索引值本身会占用较大的空间，从而加大b+树的深度，影响查询速率

②全文搜索一般不遵循最左匹配原则，会导致索引失效



##### 8、索引的优点和缺点

优点：提高检索速度

缺点：创建和维护索引耗费时间，需要占物理空间

  

##### 9、数据库锁

锁是数据库在访问数据时保证数据一致性和完整性的主要依据

数据库并发的场景：

①读读不加锁

②写写加锁

③读写使用mvcc实现（读写冲突的无锁并发控制，提高读写性能，解决脏读）



1. 表锁：开销小，加锁快，粒度大。发生锁冲突的概率高
2. 行锁：开销大，加锁慢，粒度小。发生锁冲突的概率低
3. 库锁
4. 悲观锁
5. 乐观锁
6. 共享锁：写锁。能加共享锁，不能加排他锁
7. 排他锁：读锁。共享锁，排他锁都不能加







##### 10、sql调优

- 业务层面：

①查询多数据可以使用es，redis缓存

②如果一定要用mysql：测试是条件测试、count层独立列出来



- 代码层面：


单条sql慢----索引：


②创建联合索引，减少回表（所有数据在这个索引树下查询就可以了）

③使用短索引，避免索引失效

②多表查询建立索引

③where条件字段上对表达式的操作

①建立复合索引只查询业务需要的字段

⑤优化insert语句（批量插入比单个插入效率高）

⑥在order by中不要使用 select*

⑦使用group by。使用order by null禁用

⑧避免子查询

④遵循三范式



部分sql慢----数据拆分：

①垂直拆分

②水平拆分

③慢查询



- 服务器方面：读写分离、mycat、shadingjdbc









##### 8、索引优化

①查询高且数据多的表建议建立索引。索引并非越多越好，如果增删改操作较多，慎重使用索引，因为会降低表维护的效率

②使用唯一索引，区分度高，使用短索引提高IO效率，

③如果where后面有多个字段经常被使用到，建议建立复合索引（复合索引：多列上建立索引）

避免索引失效：

①不要在索引的地方进行运算

②字符串不加“”

③避免select *

④使用or，如果or前有索引，or后无索引 就会出现索引失效

⑤范围查询（左边的列不使用索引，那么右边的键也会失效）

⑥使用like，如果是“%aa”会失效

⑦不要做列运算

⑧不要对where子句中的进行null判断、！=、<>。会放弃使用索引，进行全表扫描

***⑨不要使用join字段。超过三张表禁止使用join（相当于查询第一表，再去查询第二张表 ，再进行关联 效率低）







##### 7、mysql为什么需要遵循最左前缀法则

①如果索引关联了多列（联合索引），要遵循最左前缀法

②查询从索引的最左列开始，并且不跳过索引中的列。如果跳过某列，会造成后面字段的索引失效



##### 8、mysql索引如何定位到慢查询

- 默认10s没查出来，就会缓存到一个文件中
- show variables like‘%query%’查询慢日志的相关信息
- 一般公司都会通过自动化云平台去管理





##### 9、Explain工具定位慢查询

字段：

- key：查看是否命中索引

- Type

  all：全表扫描

   index：全表扫描索引树（如果有主键）

   range：加了条件就范围查询（最低要求）

   const：根据主键查询到结果

   ref：使用普通索引，根据索引和某个值相比较可能查出来多个符合条件的行

   eq_ref:通过主键去连表查询，最多只会返回一条数据



6、垂直拆分和水平拆分

- 垂直拆分：将不同业务放到不同数据库  （例如：订单、支付）

  通过RPC进行数据库整合

  需要考虑到分布式事务问题



- 水平拆分：就是按照数据个数进行拆分（user1、user2）

  需要考虑到扩容、查询、主键、一张表放多少数据



一张表存放多少条数据：行数超过500万或者是表容量超过2GB就可以分表



##### 10、什么时候分表分库

分表分库策略：

- 日期：优点无限扩容    缺点存放数据不均匀（双十一）
- hash：id具有连续性
- 范围：每个分表规定好个数 然后向上取整
- 枚举
- 地区（常量）



hash：

流程：Spring项目是查询的虚拟表需要 通过代理数据源（shadingjdbc数据库中间件）查询分表中的数据

优点：将数据进行均匀分摊，前提是保证id连续唯一（序列）

缺点：不支持增加表的扩容。原来查user0表，表个数增加了，查询结果也有变化了



##### 11、分表分库怎么去查询

①整合mycat或者是shadingJDBC

②查询语句需要带上分片的字段（根据id进行分片的，查询却where name=xx，就会查询每一张表，然后合并数据，会导内存溢出）



##### 12、分表分库之后如何做分页

①如果查询语句中没有分片字段 就是查询所有，交给数据库中间件来进行合并结果，再取出需要多少数据进行分页，进行返回



##### 13、分表分库之后排序怎么做

根据条件进行查询之后，还需要通过各个分表的数据进行二次排序



##### 14、mycat和shadingjdbc

- mycat是基于服务端实现代理，shadingjdbc是根据客户端改写sql语句代理
- mycat需要部署，独立ip 端口号 通过网络通讯（推荐数据量大使用）
- shadingjdbc是在项目里面集成，通过aop拦截，在本地改写sql语句，再去查询真实的jdbc
- mycat更安全，shadingjdbc效率更加高





# mybatis

##### 1、mybatis理解

- 持久层框架、半orm框架、支持定制化sql
- 可以使用简单的xml或注解来配置和映射原生关系





##### 2、${}和#{}

①${}字符串的替换，替换变量的值，statement替换

②#{}占位符，替换成？号  preparedStatement替换，所以可以防止sql注入，提高系统的安全性



##### 3、mybatis编程步骤

①创建sqlSessionFactory---创建SqlSession---通过SqlSession执行数据库操作 

②session.commit提交事务----session.close关闭会话



##### 4、resultType和resultMap的区别

①如果属性名和数据库中的字段对应的话使用resultType属性

②如果不一致的话，使用resultMap一一对应



##### 5、有哪些动态sql标签

where\foreach\set\include(复用代码)\if



##### 6、mybatis缓存机制

①一级缓存：第一次查询时，会将结果保存到一级缓存中，如果再去查询相同的数据时，直接查询一级缓存，就不用去数据库中拿数据了，默认开启一级缓存，级别是sqlsession，调用sqlSession中的增、删、改  commit()  close()  clearCache()方法都会清空缓存

②二级缓存：需要在<setting中配置cachEnable=true,手动开启缓存，实体类需要实现serializable序列化接口，级别为mapper（namespace），跨sqlSession  。设置flushCach=true自动刷新缓存

如果配置了二级缓存，查询的顺序就是：二级缓存----一级缓存----数据库



##### 7、MyBaits如何实现分页

①可以在sql里面直接写，也可以利用分页插件

②分页插件原理：使用mybatis提供的插件接口，在插件的拦截方法内拦截待执行的sql，重写sql，根据dialect方言，进行对应的物理分页。



##### 8、Mybatis的mapper接口调用时有哪些要求

①接口方法名和mapper.xml中的每个sql的id相同

②输入参数类型与parameterType的类型相同

③输出参数类型与resultType的类型相同

④nameSpace是mapper接口的类路径



# Spring

Spring是一个框架 ，同时是一个容器，还是一个生态



##### 1、spring的两大核心

①ioc（控制反转）、AOP（面向切面编程）、DI（依赖注入）

②ioc：控制反转，创建对象的权利转移，不需要去new对象，可以由spring根据我们提供的配置文件自动生成，需要对象的时候，直接去Spring容器中拿

整个bean的生命周期，从创建到使用再到销毁的过程都由容器来管理。（bean的生命周期）



ioc注入方式：构造器注入、setter注入、根据注解注入



③DI：依赖注入 （是ioc的一种实现方式，只是换了一个角度去描述，程序在运行的时候需要依赖ioc容器注入对象需要的外部资源）：把对象的属性值注入到具体的对象中

④AOP：不改变原有代码的情况下，对功能进行加强（日志、事务配置）

（ 初始化阶段执行Aware接口 和 后置处理器方法  执行初始化方法

​     AOP发生在初始化方法执行后）


##### 1、Spring如何简化开发的

①最小入侵性编程、松耦合、基于切面进行声明式编程、减少冗余代码



##### 2、代理模式

从直接调用目标对象到间接调用目标对象

静态代理：编写与其绑定的代理类，编译成字节码文件（重写）

动态代理：不改变目标对象，增强代理类。通过反射自动生成代理类



①JDK动态代理：基于接口的动态代理（spring默认）

使用jdk官方的proxy创建代理对象。实现invocationHandler接口，重写里面的invoke方法，通过其中的一个proxy类来创建需要的实例化对象

②CGLIB动态代理：基于类的动态代理

第三方cglib的enhancer类创建代理

1. 创建实现接口methodInterceptor的代理类，重写intercept接口
2. 创建获取被代理类的方法getInstance
3. 获取代理类，通过代理调用方法


因为cglib是通过继承实现的，如果类被final修饰，则不可以继承

cglib运行效率高于jdk，但是cglib创建实例化对象的速度要比jdk低，如果在单例模式下，可以使用cglib



代理模式：使用场景：日志的采集、权限控制、mybatis mapper、全局异常处理器、自定义注解





##### 3、Spring的生命周期

主要有四个阶段：实例化bean--->bean属性填充---->初始化bean----->销毁bean



1、spring启动以后，会做一个扫描，把扫描到的类，变成一个BeanDifinetion,存到BeanDifinetionMap中
2、对BeanDifinetionMap遍历进行验证，比如验证是否单例，是否原型，是否懒加载，是否有DepensOn，是否抽象，是否factoryBean，是否名字符合等
3、验证完，会去获取当前实例化的类，是否存在单例池中，有没有提前暴露，如果没有暴露的话，spring就会创建这个bean
 通过推断构造方法，对当前的类，得到一个最佳的构造方法，不同的注入模型会有不同的构造方法
3.2 通过反射实例化JAVA对象，根据JAVA对象做一些初始化工作，比如是否要对这个bean做一些BeanDifinetion的合并，是否支持循环依赖，如果支持的话，会提前暴露一个工厂类，就是存到一个二级缓存map中
3.3 然后会进行属性填充
3.4 执行aware接口的回调（例如：SpringContextAware BeanNameAware ClassLoaderAware）
3.5 生命周期初始化的回调 ，比如加了@PostConstrruct 注解的方法 实现InitailizerBean接口的
3.6 如果有AOP，会生成代理，没有的话，不会生成
3.7 存在单例池




##### 4、Spring支持bean的作用域

①singleton：单例，每个容器只有一个bean的实例

②prototype ：每个bean都可以创建一个实例

③request：每个request请求创建一个实例，请求完成之后 bean会失效且会被回收

④session：同一个session共享同一个实例，不同的会话使用不同的实例

⑤global-session：全局作用域，所有会话共享一个实例



##### 5、BeanFactory和ApplicationContext有什么区别

①BeanFactory：Spring最顶层的接口，调用起来比较麻烦，一般是spring自身使用。在启动的时候不会实例化bean，从容器中拿bean 的时候才会初始化

②ApplicationContext：是BeanFactory的子接口，扩展了其功能，程序员使用。在启动的时候就已经把bean全部实例化了



##### 6、Spring设计模式

①单例模式：创建bean

②工厂模式：beanFactory的创建

③代理模式：aop中的动态代理

④观察者模式：ApplicationEvent、ApplicationListener、ApplicationPublisher

⑤模板模式：restTemplate..

⑥装饰者模式：Wrapper、Decorator...

⑦适配器模式：aop的增强和通知

⑧包装器设计模式：项目需要连接多个数据库，而不同的客户在访问中根据需求访问不同数据库。可以根据客户的需求动态切换的数据库。



##### 7、Spring事务的实现方式和实现原理

①Spring事务是基于数据库和AOP机制

②使用@Transaction注解的bean，Spring会创建一个代理对象创建bean

③调用代理对象方法时，会去判断是否加了@Transaction注解

④如果加了就利用事务管理器创建一个数据库连接，并修改autocommit属性为false。禁止连接的自动提交

⑤执行当前方法，方法中会执行sql

⑥提交的过程中如果没有异常就直接提交。如果出现异常就回滚。



##### 7、Spring事务传播行为

事务的传播行为：多个 事务互相调用时，Spring如何处理这些事务的行为

非事务执行：不创建事务 

①required（默认）：事务存在就加入这个事务，没有事务就创建事务

②supports：事务存在加入事务，没有事物就非事务执行

③mandatory：事务存在加入事务，没有事务抛出异常错误

④required_new：不管存不存在都创建新事务

⑤not_supported：事务存在以非事务执行，不存在挂起事务

⑥never：事务存在抛出异常，不存在就非事务执行

⑦nested：事务存在嵌套事务执行，没有事务按照required执行



##### 7、Spring事务的隔离级别

②read_uncommitted:读未提交，允许事务可以看到另外一个事务没有提交的事务（脏、幻、不可重复读）

③read_committed:读已提交，保证一个事务提交之后，才能被另外一个事务读取，但是能够看到该事务的更新（幻读，不可重复读）

④repeatable read：可重复读，保证一个事务提交之后，才能被另外一个事务读取。但是不能看到对已有记录的更新（幻读）

④serializable：事务在执行的时候看不到任何一个事务对数据库的更新（库锁）

如果数据库和spring都配置了隔离级别 以spring为主



##### 7、Spring事务什么时候会失效

①bean对象没有被spring容器管理

②方法的访问修饰符不是public

③方法内部不能调用

④数据源没有配置事务管理器

⑤数据库不支持事务

⑦异常类型错误或配置错误

⑧方法中有异常不要try往上抛



##### 8、Spring通知类型

①前置通知：在切点之前

②后置通知：在切点之后执行

③环绕通知：自定义位置

④最终通知

⑤异常通知：异常时执行



##### 9、spring单例bean存在线程安全问题吗

bean无状态，线程安全。

bean有状态，线程不安全。（某些方法操作bean属性会发生变化，这就是有状态）

两个线程都要去修改这个属性，修改的值不一样的时候就会出现线程不安全的问题。



②解决：使用ThreadLocal局部变量，保存在ThreadLocal中。

​              如果需要多个变量的共享，加锁synchronized、lock、cas来实现线程的同步（效率低）

尽量不要在bean中声明有状态的成员变量。



##### 10、@Resource和@Autowired区别  @Qualifier使用场景

①@Resource:按照属性名称进行依赖注入（只能放在属性上）

②Autowired：先根据类型去寻找，如果有多个，再用@Qualifier根据名字依赖注入

@Qualifier：与@Autowired联合使用，根据指定id在spring容器中匹配对象







##### 12、SpringBoot有几种定义bean的方式

- @Bean
- @Component
- @Controller
- @ControllerAdvice
- @Import
- @BeanDefinition




##### 14、spring的循环依赖问题

当spring实例化X的时候，首先对X做一些基本的验证，验证完看一下X有没有提前暴露，就是X对应的ObjectFactory(工厂 类)，有没有提前暴露，一开始肯定没有，继续往下执行，X推断一个构造方法，通过构造方法，把X实例化出来，X会提前暴露出来，暴露的不是一个单纯的X ，暴露的是由X生成的创建出来的ObjectFactory对象，然后会做X的属性填充，此时填充Y ，此时Y并没有存在spring容器，就会去做Y 的生命周期构造，Y也是从BeanDifinetionMap拿出来，然后做一些判断验证，验证完，判断Y有没有提前暴露，一开始也是没有提前暴露的，所以推断Y的构造方法，实例化Y ，Y提前暴露，Y的属性填充X ，发现X并不存在单例池中，因为X的流程此时走到一半，还没走完，一开始的流程又走一遍，但是此时不一样的是，X已经提前暴露了，就能拿到X所对应的ObjectFactory

为什么不直接暴露X，而是暴露X的ObjectFactory

如果缓存一个X，那获取的时候，就是一个单纯的X ，程序员很难对他进行扩展，而如果暴露的是一个ObjectFactory,spring内部通过实现BeanPostProcessor这个接口，能够对ObjectFactory在产生X的过程当中，程序员可以扩展，可以干预，可以得到一个自己想要的X对象



- Spring一级缓存作用

也叫单例池singltonObjects：存放已经经历了完整生命周期的bean对象。成员属性都是由值的

- Spring二级缓存作用

earlySingletionObjects：存放早期暴露出来的bean对象，Bean的生命周期还没结束，属性还未填充完整

- Sping三级缓存作用




##### 17、Bean工厂处理器、后置处理器区别

1. Bean工厂处理器是在实例化Bean之前执行，可以通过工厂Bean处理器修改Bean的定义信息
2. Bean后置处理器 是在 init前后执行 ，可以修改Bean对象为代理对象 从而对我们方法实现增强





# SpringMVC

##### 1、对mvc的理解

①使用的三层架构，module、view、controller。解耦合、提高代码的回复

②其中module是模型（定义实体对象）、cotroller是控制器（逻辑处理）、view是视图



##### 2、Spring常用的注解

①RequestBody：处理url请求，作用于类或者是方法上。作用于父类上：请求方法都以该地址为父路径

②RequestBody:接收http请求的json对象。将json转java

③ResponseBody：转化为json传给用户

④PathVariable：获取路径参数

⑤RequestParam：用于对传入参数的一些限制

⑥ControllerAdivce：标注在一个类上，表示这个类是全局处理类

@ExceptionHandler：标注在异常处理类的方法上



##### 3、SpringMVC的常用组件

①前端控制器DispatcherServlet：接收请求、响应结果，相当于转发器

②处理器映射器HandlerMapping：根据请求的url来查找handler

③处理器适配器HandlerAdapter：负责执行handler

④处理器handler：处理业务逻辑的java类

⑤视图解析器ViewResolver：进行视图解析，根据视图逻辑名将ModelAndView解析成真正的view

⑥视图View：view是一个接口，它的实现类支持不同的视图类型，jsp、freemarker



##### 4、SpringMVC执行流程

①用户收到请求传给前端控制器

②前端控制器调用处理器映射器找到handler

③处理器映射器返回处理对象给前端控制器

④前端控制器请求处理器适配器执行handler

⑤处理器适配器调用自定义处理器，自定义处理器得到参数返回给处理器适配器

⑥处理器适配器返回moduleAndView给前端控制器

⑦前端控制器请求视图解析器，返回view对象给前端控制器

⑧前端控制器进行渲染视图，然后返回结果给用户





##### 4、SpringMVC转发和重定向的写法

①转发：在返回值前面forword

②重定向：在返回值后面redirect



##### 5、SpringMVC异常处理器的思想和实现方式

①方法一：创建一个自定义异常处理器，实现handlerExceptionResovler接口，并实现里面的方法，将这个类交给spring容器管理

②方法二：在类上加@ControllerAdvice注解（表明这是全局异常处理类），在方法上加上@ExceptionHandler里面的value属性可以处理的异常类型





##### 6、通过转发将数据传给前台

①在request域中进行传递request.setAtrribute

②使用model进行传值：module.addAttribute

③使用modelMap进行传值：modulMap.put

④使用modelAndView设置视图和数据 ，进行返回



##### 7、SpringMVC中的拦截器的使用步骤

①创建一个类实现handlerInterceptor接口，重写里面的抽象方法

- preHandle：在调用处理器之前调用该方法
- postHandle：在处理器调用之后调用该方法
- afterHandle：在前端控制器渲染完成之后调用该方法

②注册拦截器：在配置文件中自定义拦截器



##### 8、SpringMVC上传文件的步骤、三要素

步骤：

- 加入commons-fileupload包
- 配置文件上传解析器，id必须为multipartResolver
- 后端接收的文件参数类型必须为MultipartFile，需要与前端保持一致

三要素：

- 表单必须为post提交方式
- enctype属性改为：multipart/form-data
- 必须有一个type属性为file的input标签，其中需要一个name属性，如果需要上传多个文件需要添加multiple属性




##### 9、如何解决post、get乱码问题

①解决post乱码：在web.xml中配置一个characterEncodingFiler，设置为utf-8

②解决get乱码：

- 修改tomcat文件添加编码与工程编码一致
- 对参数进行重新编码







# SpringBoot

##### 1、Spring与SpringBoot

①SpringBoot是Spring的子框架，在Spring 的基础上进行了优化

②解决了maven冲突问题。引入了父工程，对版本进行集中的控制

③起步依赖

④自动配置

⑤内置tomcat



##### 2、starter的执行原理

①启动的时候会扫描jar包中的spring.factories

②根据文件的配置去加载自动配置类

③Spring读取之后，会创建这些类的对象，放到Spring容器中，后期直接从Spring容器中获取对象



##### 2、Springboot启动流程

①creatApplicationContext创建ioc容器

②loadsourceClass加载源配置类（被SpringbootApplication修饰的类）

③加载并处理所有的配置类

④实例化所有的单例bean

⑤启动web服务器



##### 3、SpringApplication类作用及run()方法作用

①SpringApplication整合了其他框架的启动类

②调用run方法，将当前启动类的字节码传入，以及main函数的args函数

③通过获取当前启动类的核心信息，创建ioc容器



##### 4、SpringBootApplication注解

①有四类注解

②第一类：JDK原生注解

- @Target(ElementType.TYPE):当前注解的使用范围
- @Retention(RetentionPolicy.RUNTIME):生命周期
- @Documented：声明在生成doc文档时是否带着注解
- @Inherited：声明是否子类会显示父类的注解



③第二类：@SpringBootConfiguration

- 本质就是@Configuration    定义该类是个配置类功能相当于xml
- @Configuration与@Bean搭配使用，能够替代xml文件，可以理解为创建ioc容器



④第三类：@EnableAutoConfigration

- 点开源码本质就是一个@import，自动导入功能
- @EnableAutoConfiguration与@import搭配使用，将所有符合条件的bean加载到ioc容器中
- 会根据类路径中的jar依赖为项目进行自动配置



⑤第四类：@ComponentScan包扫描功能





##### 5、SpringBoot如何自动配置

当我们在配置类中加入@SpringBootApplication的时候，这个注解是一个复合注解，里面包含了@EnableAutoConfiguration注解内部有一个@import注解，这个注解才是自动配置的关键

①@Import导入一个类AutoConfigurationSelector，这个类里面有一个方法selectImports方法

②这个方法会扫描导入的所有jar包下的factories文件（SpringFactories机制），解析里面的内容key=value，将列表中的类创建，并放入Spring容器中



##### 7、SpringBoot中的配置文件

①有哪些配置文件

- bootstrap.yml
- application.yml



②区别

- bootstrap优先级高，由Springcontext加载，它里面的属性不能被覆盖



③读取配置文件的方式

- 读取默认配置文件：注入Enviroment类，通过environment.getProperties(key)，获得相应的value。@Value(${key.value})直接读取


- 读取自定义配置文件：1、@ConfigurationProperties("前缀")  2、PropertySource("指定配置文件") 3、@Component包扫描




##### 9、SpringBoot常用注解

①@SpingBootApplication：封装了核心注解

②EnableScheduling：通过@Import将Spring调度框架相关的bean加载的IOC容器

③@MapperScan：完成对mybatis接口的扫描

④@RestController（@RequestBody+@Controller）、@RestMapping、@RequestMapping、...



##### 10、Springboot有哪种读取配置的方式

- @PropertySource
- @Value
- @Environment
- @ConfigurationProperties




##### 11、SpringBoot如何解决跨域问题

通过实现WebMvcConfigurer接口然后重写addCorsMappings方法解决跨域问题



什么是跨域；协议、域名、端口其中之一不一致就是跨域



##### 12、微服务中如何实现session共享

①spring Session+redis来实现session共享

②将session统一保存到redis上，当各个微服务对session有相关的读写操作时，都去操作redis上的session，实现session共享

③Spring Session是基于Spring上的代理过滤器实现





##### 13、SpringBoot是如何启动Tomcat的

①创建一个SpringBoot容器

②利用ConditionalOnClass判断当前classPath中是否存在tomcat的依赖

③如果存在，则会生成一个启动tomcat的bean

④容器创建完成之后，获取tomat的bean。并获取tomcat对象绑定端口，启动tomcat



##### 14、定时器

①使用@Schedule注解,在方法上。写一个cron表达式,来确认什么时候来进行定时器的任务执行,启动类上添加@EnabaleSchedule,开启定时器任务功能
②在线程池上面添加@Schedule,然后使用线程池定义我们需要执行的任务,再进行任务的调用即可
③使用ScheduledTaskRegistrar 实现可配置化的定时任务，自定义CompleteScheduleConfig 继承 SchedulingConfigurer

④xxl-job








# Springcloud

继承SpringBoot 提供了很多优秀的服务：服务发现、注册、统一配置中心、负载均衡、网关、熔断器等微服务治理框架

##### 1、Springcloud优势特点

优势：

①稳定性、持久性都可以保证。提高开发效率，能够实现需求

②更新快，后期支持很给力

特点：

①单一职责：服务对应相对的业务

②面向服务：提供rest接口

③自治：相互独立、互不干扰

④隔离性强：服务调用要做好隔离、容错、降级



##### 2、Springcloud组件

###### 2.1注册、配置中心Eureka 和Nacos

共同点：

①支持服务的注册和拉取 ②都支持心跳监测

区别：

 ①nacos支持由客户端或服务端发出的健康监测 ，eureka支持客户端发出的心跳

②nacos临时实例采用心跳模式，非临时实例采用主动监测模式

③nacos集群默认采用AP模式（强调数据的可用性），当集群中存在非临时实例时，采用CP模式（强调数据的一致性和可用性）。Eureka只支持是AP模式

a：可用性         p：容错性        c：一致性

④euraka30s发送心跳监测，90s没有心跳就宕机



###### 2.2ribbon负载均衡

①它会自动根据某种算法去分配连接的机器，是一个客户端负责均衡器

②默认是轮询策略

常见负载均衡算法：①轮询 ②加权轮询 ③随机④最少连接⑤原地址hash



###### 2.3Hystrix熔断器

导致代码无法运行，服务挂了。熔断器就是解决无法正常访问服务提供的一种策略

提供了两种策略

- 服务降级：当系统发现压力过载时，通过关闭或者是限流服务来减轻系统的压力。

- 服务熔断：

  当服务a在调用服务b不可以时，上游服务a为了保证自己不受影响，从而不再调用服务b，直接返回一个结果，减少服务ab的压力，直到服务b恢复。

  ①熔断关闭：关闭状态，所有访问正常进行

  ②容器打开：打开，所有请求都将会被降级。 hystrix会对请求次数进行计算。当一定时间内失败请求达到阈值（50%），则触发熔断

  ③半熔断状态：open状态不是永久的，打开后会进入睡眠状态（5s），随后断路器会自动进入半开的状态

  相同点：都是防止服务器崩溃、让用户体验某些服务不可用

  不同点：熔断是下游服务故障触发，降级是降低负载



###### 2.4Feign远程调用

- 服务和服务之间调用使用feign
- feign组件集成了ribbon负载均衡（默认开启，轮询）
- 被调用的微服务提供一个接口@FeignClient。调用方的启动类上@EnableFeignClients开启feign


ribbon和nginx区别



###### 2.5gateway网关

功能：请求路由、权限控制、限流、负载均衡

请求路由：所有的请求都要经过gateway，但是网关不会去处理业务，会把请求发给每一个服务，这是路由

权限控制：网关作为微服务的入口，需要校验是否有资格，没资格就拦截，有资格就放行

限流：请求流量过高时，通过网关进行流量控制，将流量设置到服务能够接受的速率

负载均衡：当压力过大是，会分担服务器的压力，防止服务器压力过大而崩溃





##### 3、SpringCloud和dubbo区别

- Springcloud是Apache下的，Dubbo是阿里的
- 技术方面：Dubbo侧重于服务调用，属于RPC框架。Springcloud提供了很多组件
- SpringCloud可以整合Dubbo




##### 4、Eureka和zookeeper的区别

- eureka是ap（可用性和容错性）   zook是cp（一致性和容错性）




##### 5、CAP理论

c：强一致性

A：可用性

P：分区容错性



6、docker

- docker可以解决微服务中各种依赖组件部署时产生冲突的问题
- 包括依赖兼容问题、运行环境冲突问题





# redis

##### 1、redis的优点

- 纯内存操作，性能高
- 单线程操作，避免频繁的上下文操作。6.0版本之后引入了多线程是指网络请求的过程采用了多线程，但是键值读写还是单线程
- 采用了非阻塞IO多路复用机制（epoll），IO多路复用只有单个线程，通过跟踪每个IO流的状态，来管理多个IO流
- 高效的内存结构




##### 1、为什么要使用redis

- 高性能：直接读缓存
- 高并发：直接操作缓存能够承受的压力远远大于数据库




##### 1、redis的数据类型

①String：普通字符串类型

②list：有序 可重复 ，双向链表（双向链表）

③set无序 不可重复 (hash+数组)

④sorted set按照分数排序，可以重复（ziplist+跳表skiplist）

⑤hash：存储对象（ziplist+hash）



ziplist的满足条件：键值数量小于128  ，元素长度小于64字节

跳表：在有序链表上建立索引，每两个节点抽取一个节点在上一级，形成多级索引（冗余字段）



##### 2、redis中的list和Zset区别

①list数据结构是链表型的，类似于LinkedList，受链表的影响，所以插入效率很高而且插入有序、可以重复。

它的每一个节点都保存上一个节点和下一个节点的指针，相当于数组型的链表来说更加节约空间。在redis中有一种压缩列表存在的zipList，它把少量的元素使用一个连续的内存空间来进行存储，这一点的话又和我们数组是一样的可以节约空间，而list结构是由多个zipList串起来组成的quickList

②Zset，按照分数排序，它的每一个成员都有一个分数来对应。





##### 3、缓存穿透、击穿、雪崩

①缓存穿透：大量的请求访问一个本身不存在的数据

解决：

- 缓存空对象：没有查找数据，在缓存中也写入null（空字符串），缺点：导致内存耗尽

- 使用布隆过滤器：bit位的数组，每一个bit非0即1，主要判断key是否存在。加布隆过滤器拦截一些不存在的key

  添加数据时，计算hash值得到对应的bit位


布隆过滤器实现：

位图，每一个bit非0即1

1. 将数据库数据加载到布隆过滤器中
2. 当有请求来的时候先去布隆过滤器查询，判断查询数据是否存在
3. 如果不存在，直接拦截给客户端
4. 如果存在，则查询缓存或者是数据库（将数据库中查询的数据返回给客户端，并且缓存到redis中



布隆过滤器误判：

1. hash算法问题，布隆过滤器是由二进制和hash算法组成，不同的hash值可能存在一样的hash结果。不能获取元素本身
2. 解决：添加多个hash算法，减少hash碰撞的概率




②缓存击穿：一份热点数据缓存失败，突然涌入大量的访问请求，导致服务崩溃

解决：

- 分布式互斥锁：只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重写从缓存获取数据即可。
- 永不过期：没有设置真正的过期时间，所有不会出现热点数据key过期后产生的问题。





③缓存雪崩：大面积的请求访问失败，直接访问数据库，导致数据库压力过大甚至宕机。

- 互斥锁排队

跟缓存击穿思路一样，同一时间只让一个线程构建缓存，其他线程阻塞排队。

- 缓存预热

系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。

- 双层缓存策略

主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。

备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。

- 均匀过期

在过期时间上加一个随机数，让缓存失效的时间尽量均匀





##### 5、redis的单线程架构

①redis的网络IO和键值对读写是单线程的，其他功能如持久化、异步删除等都是依赖其他线程来执行的，事实上底层不是单线程

②采用单线程进行读写操作，避免线程切换和锁竞争带来的消耗

③reids大部分操作存在于是在内存中，所有性能高

④IO多路复用，实现在网络的IO中能够处理大量并发请求，实现高吞吐率



##### 6、redis项目中的使用场景

①数据丢失

②只能解决部分并发问题

③故障恢复

④分片集群



##### 7、单节点redis问题

- 主从
- 哨兵




##### 8、save和bgsave

- save：同步 ，会阻塞redis其他命令，不消耗内存
- bgsave：异步，不会阻塞redis其他命令，不阻塞客户端命令(background)




##### 8、redis持久化机制

8.1RDB

原理：

- redis数据备份文件，把内存中所有数据都记录到磁盘中（快照方式 dump.rdb文件）
- 当redis出现故障重启后，从磁盘读取数据，来恢复。



RDB方式bgsave流程：

- fork主进程得到一个子进程
- 子进程读取数据并写入新的RDB文件
- 用新的RDB文件替换旧的RDB文件



执行时机：

- 执行save、bgsave命令(默认)
- redis停机时
- 触发RDB条件时（例：save 60 1000：60秒类至少执行1000次修改触发RDB

优点：

- 体积较小，恢复速度快

缺点：

- 数据丢失：时间间隔长。两次RDB之间的读写数据可能丢失
- 耗时：fork子进程、压缩RDB文件、写出RDB文件很耗时。




8.2AOF

默认关闭需要手动开启：在redis.conf中修改appendonly  no为 yes

文件写入AOF机制：

- appendsync  always写一条马上存一条     
- appendsync  everysec设置多久执行一次 1s（默认）
- appendsync no：有操作系统来处理

优化：使用bgrewirteraof命令：可以让AOF文件执行重写功能

原理：

- 追加文件，每一次写命令存入磁盘，记录到aof文件中，将缓冲区的内容写入磁盘。
- 数据恢复：直接从上到下执行aof文件（appendonly.aof）

优点：

- 刷盘策略相对完整
- 时间间隔短，数据丢失少
- 主要是磁盘IO，消耗低，但是重写会占用大量cpu资源（整个aof文件在后台生成）


缺点：

- 体积大，宕机恢复速度慢



##### 9、RDB和AOF区别

①RDB是把内存中高端数据记录到磁盘中，通过快照的方式。AOF是通过追加文件，每一次写命令记录到磁盘。

②RDB两次备份之间会有数据丢失的风险，不完整。AOF刷盘策略相对完整。

③RDB有压缩成二进制文件，文件体积小。RDF记录指令，文件体积大。

④RDB宕机速度快。AOF宕机速度慢。

⑤RDB数据完整性低，所以数据恢复优先级也低。AOF反之。

⑥RDB大量CPU和内存消耗，占用大量资源。AOF主要是磁盘IO资， 消耗低，但重写是会占用大量cpu资源和内存消耗

⑦RDB：容忍数据丢失，追求速度快。AOF：对数据安全性要求比较高。



4.0之后混合持久化：aof-use-rdb-preamble yes（必须开启aof）

- 在aof重写时，以二进制的格式存入aof
- 在此期间如果有新的命令过来，就以aof的格式写入aof文件



master中最好不好持久化，在slave节点上开启aof备份数据



#### 10、redis高可用

##### 10.1全量同步

①第一次连接时，执行全量同步。将master节点的数据全部拷贝到slave节点。

②slave节点断开时间太久，repl_baklog中的offset已经被覆盖时。



##### 10.2redis主从复制原理

①判断第一次连接：判断repid是否一致。通过replid数据集的表，如果id一致则说明是同一数据集。（每一个master都有一个replid，slave继承master中的repid）

②第二：master执行bgsave，生成RDB，记录RDB期间的所有命令，发送RDB文件。slave清空本地数据，加载RDB文件。

③第三：master发送repl_baklog中的指令。slave执行指令。

（repl_baklog中的数据越大，偏移量随之增大。slave的offset小于master的offset，说明slave数据落后于master，需要更新）



##### 10.3主从复制的优缺点

- 主机会将把数据同步到从机，可以进行读写分离。master用来写，slave用来读
- redis不具有自动容错和恢复功能。集群达到上限时，在线扩充会很麻烦




##### 10.4什么时候使用增量同步

- 创建第一次连接，repid不同
- slave节点断开又恢复，且在repl_baklog中的offset已经被覆盖时。



##### 10.5增量同步原理

①第一阶段：判断replid是否一致

②第二阶段：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave。



##### 10.6全量同步和增量同步区别

①全量同步：master将完整数据生成RDB，发送RDB到slave，命令记录到repl_baklog发给每一个slave。

②增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave。



#### 11、哨兵

##### 1、哨兵的作用

①监控：不断检查每一个节点的状态

②自动故障恢复：master故障，sentinal将一个slave提升到master。

③通知:Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端



##### 2、如果判断redis实例是否健康

①服务状态监测：sentinal是基于心跳机制监测服务状态，每间隔一秒先集群的实例发出ping。

②如果超出时间没有回应则任务是主观下线。如果超过指定数量的sentinal都认为实例主观下线，则该实例为客观下线。



##### 3、如何选举master

①断开时间越长丢失数据越多，直接排除slave

②判断slave-priority值，越小优先级越高。如果slave-priority一样，就判断slave的offset，越大说明数据月新，优先级越高。如果offset相同就判断slave节点的运行id大小，越大优先级越高



##### 4、如何实现故障转移

①选定一个slave作为新的master，发送 slaveof no one

②让所有节点执行slaveof新master（认主）

③修复故障节点配置。添加slaveof新master



##### 12、淘汰策略

内存超过maxmemory，redis怎么处理？

为什么key没设置过期时间被主动删除了？

1.noeviction（默认）
不进行数据淘汰，当缓存被写满时，直接返回错误。

针对过期key设置：

2.volatile-random随机删除。
3.volatile-ttl越早过期的越先被删除。
4.volatile-lru淘汰最近很久没有访问的数据
5.volatile-lfu 淘汰最近访问次数最少的数据

针对所有key设置：

6.allkeys-random所有键值对中随机选择并删除数据。

7.allkeys-lru  lfu
LRU：时间最远（很久没有访问）
LFU：次数最少（访问次数最少）



LRU常用，如果存在大量的热点缓存数据，使用LFU

##### 13、删除策略

redis设置过期时间，到了时间就删除。

修改key值时如果没有设置过期时间，这个key就会永不过期

①定时删除：key过期就删除

优点：节约空间     缺点：cpu资源占用高

②惰性删除：下次get时删除,以空间换时间。

1. 如果未过期，返回数据
2. 如果已过期，删除返回不存在

③定期删除：给出一定的时间来随机扫描，扫描到过期的key就删除。如果过期的key比较多，下次还是扫描此数据库。



##### 14、分片集群

主从和哨兵可以解决高可用、高并发读的问题。但是仍然存在海量数据存储问题，高并发问题。

特点：

①集群中有多个master，master中存储不同数据

②master中有多个slave节点

③master之间通过ping监测健康状态

④客户端请求可以访问集群任意节点，最终都会被转发到正确节点



##### 15、散列插槽

redis会把每一个master节点映射到16384个插槽上。

Redis如何判断某个key应该在哪个实例？

①将16384个插槽分配到不同的实例

②根据key的有效部分使用CRC计算哈希值，对16384取模（得到具体槽位），寻找插槽所在实例即可



##### 16、redis的分布式锁

redis中使用sentnx命令来实现分布式锁

- 如果key不存在 返回1。如果key存在 返回0。
- 原理：多个jvm同时在redis中写入一条setnx相同的key，谁写入成功谁就获得锁
- 获取锁失败：重试多次失败的就导致jvm阻塞，这个锁被释放（key被删除）。没有获取到锁的jvm重新获取锁的状态


如何避免死锁问题：设置过期时间，等key过期进行重试，redis先天性解决死锁问题

如果key已经过期，但是业务还没执行完：过了三分之一之后，代码还没执行完，就会开启看门狗机制，每隔10s不断续命延迟30s，直到最后释放锁



##### 16、分布式ID是什么

①在分布式架构中，可能会出现id冲突

②利用redis的自增命令，nosql性能高

③雪花算法：通过某台机器在某一毫秒对某一个数字进行自增，能保证系统id唯一性

雪花算法缺点：机器出现时钟回拨（时钟倒退）。可能会导致一致 但是发生的可能性很小

解决时钟回拨：使用Zookeeper持久顺序节点的特性自动对snowflake节点配置workerID



##### 17、redis数据库如何保持一致

①更新mysql数据，手动清理redis缓存，再重新查询最新的数据，同步到redis中

②更新mysql数据，使用mq通知，同步数据到redis

- 缺点：延迟概率大
- 优点：解耦（因为需要判断redis是否为空，读取mysql再同步到redis，响应变慢。mq中自带重试策略）

③订阅mysql binlog采用mq异步将数据同步到redis中

优点：不需要使用代码同步，具有全局意识

缺点：使用单线程进行同步，也会有延迟

- 当mysql主节点发生变化时，发送同步binlog文件给canalServer端
- canalServer端相当于mysql的从节点，订阅binlog文件
- canalServer端使用kafka将数据同步到redis中

④延时双删

①t1线程先删除缓存，t2线程读取缓存为null，将数据库的数据同步到redis中

②t1线程更新数据库中的数据，t3查询线程发现是旧数据（t2

这个时候t3读取的是老数据

使用延时双删解决：延迟一段时间，再删除这个缓存

延时时间：t2线程执行的时间就是延时时间

缺陷：第一次删除时间是很难确定的（使用少）



流程：先删除redis缓存，更新数据库中的数据，延迟一段时间再删除redis中的缓存



⑤双写一致

##### 18、mysql与redis是否存在延迟问题

①必然会存在延迟问题，但是不能延迟很久（通过网络的形式都会存在延迟）



##### 19、双写一致

什么是双写：先去更新DB再去更新redis。所有操作都是一致的

当两个线程同时去写操作，只有一个线程能够写成功，因为存在行锁

缺陷：数据不一致

解决：事务在提交的时候才会释放行锁，mysql和redis同时修改之后，才释放行锁。最后变成单线程 效率低

这个时候使用分布式锁来解决：多个线程同时来执行写业务



##### 20、redis应用场景

①缓存

②分布式锁

③排行榜



##### 21、大key

key对应的value很大，占用的redis空间很大

大key产生：

- redis中的数据结构使用不合适
- 未及时清理垃圾数据

危害：

- 阻塞请求
- 内存增大
- 阻塞网络

如何识别：

- 使用redis自带的命令识别：（redis-cli 加上bigkeys参数）

如何解决大key：

- 进行拆分
- 对定时清理大key





##### 22、删除key会阻塞redis吗

会阻塞

- 如果是删除字符串时间复杂度为o(1)一般不会阻塞，但是如果是大key就会阻塞
- 如果删除hash、集合、列表这些的话，就要一个一个元素的去删除，时间复杂度为o（n）。数据量大的话就会阻塞



##### 23、redis中死循环阻塞

使用randomkey命令，惰性删除的时候，如果有大量的key过期，就会循环很久

slave不会自己删除key，当一个key要过期的时候，master会先删除 ，然后发送del命令给slave。

c假设redis中存在大量已经过期未清理的key，那么slave执行randomkey命令去找key，如果每次运气不好，就会找到过期的key，从而可能会导致死循环，阻塞redis。

5.0之前的bug，5.0之后修复控制次数，不管找不找得到，都会退出循环



##### 24、redis宕机数据全部丢失

数据丢失的问题：

- 主从+哨兵
- master没有开启持久化
- redis继承使用supervisor管理，并配置为宕机自动重启

导致:

- master宕机，哨兵还未切换，master进程立即被supervisor自动重启
- master是一个空实例
- slave为了与master保持一致，也变成了空实例。导致缓存雪崩

解决：

- 不应该配置自动重启，而是等哨兵把某个slave节点切换为主节点。再重启之前的主节点变为slave节点



##### 25、线上如何备份

- 写crontab定时调度脚本，每小时copy一份到文件到另外一条机器，保留48小时数据
- 挑一个时间把当天的数据放到一个目录中，保留最近一个月的数据
- 把太旧的备份删了



##### 26、redis主从复制风暴

一个主节点太多的从节点，导致数据同步时master节点压力过大



##### 27、redis网络抖动导致主从频繁切换

配置cluster-node-timeout时长，超时才认为出故障



##### 28、为什么要三个master

如果只有两个，达不到选举条件



##### 29、批量操作指令

mset，但是要设定所有的key落在一个slot上



##### 30、Lua脚本

脚本里面的key都要落在同一个master节点上，{user1}，lua脚本才能在redis集群中正常执行



##### 31、海量数据存redis

数据冷热分离、查询到的数据延期











# MQ

消息队列，事件驱动中的broker简单方便，高度耦合，扩展性差



##### 1、消息中间件的区别

①rabbitMQ（可靠）

- 缺点：对消息堆积不太友好，当大量的数据堆积时，可能会出现性能下降
- 优点：消息可靠性高，功能全面

②kafka（高效）

- 缺点：如果数据没有那么多的话，时延反而会更高。会丢失数据，安全性不高
- 优点：吞吐量大，效率高

③rocketMQ

- 缺点：开源版本功能不如商业版本，官方文档不够成熟
- 优点：高可用、高吞吐、高性能 。功能全面




##### 1、项目中哪用到的mq

异步发短信、扣库存、贷款金额审核

例：

①多线程方式：可以使用线程池来完成，但是消耗cpu的资源（在同一个jvm中完成）

②mq方式：

- 服务端向客户端发送一个request请求。接收到了请求之后插入一条会员信息
- 服务端（生产者）发送一个msg消息给mq，消费者去mq中拉取消息
- 拉取到消息之后再发送短信、优惠券




##### 1、为什么要使用mq

①异步处理

②解耦

③流量削峰



##### 2、交换机的作用

- 接收publisher发送的消息
- 将消息按照规则路由的绑定的队列
- 消息的路由不是消息的存储，只是负责消息的转发





##### 3、MQ的模式和特点

①简单模式：一个生产者、一个消费者

②工作模式：一个生产者、多个消费者

③订阅模式：允许同一信息发送给多个消费者，加入了多个exchange

订阅模式又分为三种：广播、路由、话题

- 广播模式：接收到的所有消息，只发送绑定了queue的每一个队列
- 路由模式：将收到的消息发送给指定的Qeueu（通过Exchange对比bindingkey与routingkey是否一致，发送指定的消息）
- 话题模式：topic的routingkey可以是多个单词的列表




##### 4、消息队列中存在的问题

①消息可靠性：消息至少被消费一次

②延迟消息问题：消息如何延迟投递

③高可用问题：如何避免单点mq故障而导致的不可用问题

④消息堆积问题：如何解决数百万消息堆积，无法消费的问题



##### 5、消息丢失的原因

只要有消息传递的地方，就有可能丢失。

①生产者发送的消息没有送达exchange

②消息到达exchange未送达queue

③mq宕机，queue将消息丢失

④consumer接收到消息未消费就宕机



##### 6、如何保证消息的可靠性

- 生产者确认机制（ack）

- 消费者确认机制

- 失败重试机制

- mq持久化（到硬盘）


###### 6.1生产者确认机制

必须给每个消息指定唯一的id，消息发送到mq后，会返回一个结果给发送者，表示消息是否处理成功。

- 生产者--交换机 confirm机制

  成功投递到交换机，返回ack，未成功返回nack

- 交换机--队列 return机制

  消息投递到交换机了，但是 没有路由到队列。返回nack，及路由失败原因。

- 队列--消费者 ack机制 选择自动确认

  突然宕机，造成数据丢失，必须开启消息持久化机制


###### 6.2消息持久化

如果突然宕机，会造成消息丢失，确保消息在mq中安全保存，必须开启消息持久化机制。

解决：

- exchange持久化
- queue持久化
- message持久化



###### 6.3消费者消息确认

mq投递消息给消费者，消费者获取消息后，返回ack给rabbitMQ，MQ删除消息，消费者宕机，消息尚未处理。

三种模式：

none模式：消息投递是不可靠的，可能丢失

auto模式：类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack

manual模式：自己根据业务情况，判断什么时候该ack





###### 6.4消费者失败重试机制

Spring中的retry机制，（并设置MessageRecover，多次失败将消息投递到异常交换机。人工处理）

requeue

当消费者出现异常后，消息会不断requeue（重入队）到队列，在重写发送到消费者，如果再次出现异常，再次requeue，无限循环，导致mq的消息导出飙升，带来不必要的压力



###### 6.5外部因素mq消息丢失

如何检测：

- 大部分的消息客户端都支持拦截器机制，生产者发送消息时拦截注入序号到信息中
- 消息具有有序性，如果需要没有连续递增，那肯定丢失了消息。还可以通过丢失的消息来判断丢失的哪条消息，排查原因
- （分区）多个生产者发送消息顺序是不好协调的，需要在每个生产者分别生成各自的序列号，并附加上生产者的标识

如何避免：

- 生产阶段：捕获错误消息，重新发送
- 存储阶段：配置刷盘和复制相关参数，将消息写入副本磁盘，确保消息不会因为某个broker宕机发送磁盘的损坏
- 消费阶段：处理完逻辑，给消费者确认

解决：

6如何保证消息的可靠性

- 持久化消息到硬盘

- 生产者确认、消费者确认

- 消费者失败重试




##### 11、死信交换机

(解决延迟消息问题)

###### 11.1死信

①消息被消费者reject或者返回nack

②消息超时未消费

③队列满了

死信交换机：队列中的死信投递到死信交换机。



###### 11.2如何绑定死信交换机

①配置dead-letter-exchange属性

②设置死信交换机与死信队列的RoutingKey



###### 11.3TTL存活时间

time to live 

消息超时的两种方式是？

- 给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信
- 给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信



11.4消息20s后才消费者才收到消息

- 给消息的目标队列指定死信交换机
- 将消费者监听的队列绑定到死信交换机
- 发送消息时给消息设置20s



##### 12、延迟队列

在指定时间要消费的队列

延迟队列 = TTL队列+死信交换机

概述：使用两个队列，一个队列接收消息不消费，等待指定时间后消息死亡，再由该队列绑定的死信exchange再次将其路由到另一个队列提供业务消费



实现：

- 安装DelayExchange插件，实现延迟队列。

概述：当一个队列设置了死信exchange 后，这个队列的死信都会被投递到死信exchange中，然后可以再次路由到其他队列中（如果指定了死信routing key 则死信消息routing key 变为设置的routing key，未设置则为原始 routing key）。

- 声明交换机，添加delayed属性为true。发送消息时，添加x-delay头，值为超时时间。



使用场景：

①延迟发送短信

②用户下单，如果用户15分钟未支付，自动取消

③预约



##### 13、惰性队列

###### 13.1消息堆积

- 生产者的速率和消费者速率不匹配就会产生消息堆积
- rabbitmq如果消息被消费成功，立即删除。但是kafka或rocketmq不会立即被删除

解决消息堆积：

①增加消费者，提高消费速度。（集群）

②扩大队列容量，提高上限。

③批量获取消息

④使用惰性队列



###### 13.2惰性队列

- 接收到消息后存储在磁盘而不是内存，消费者消费消息的时候才会磁盘中读取并加载到内存
- 支持百万条数据存储 

优点：

①基于磁盘存储，消息上限高

②没有间歇性page-out，性能稳定

缺点：

①消息时效性低。

②性能仅限于磁盘的io



##### 14、mq的重复消费和消息幂等性

问题产生：消费者消费失败，需要使用重试机制，会导致消息可能会重复消费

①重复消费：当消费者消费完成后，会通过确认机制发送ack，因为某种原因，可能会导致mq没有收到ack，导致再次发给消费者 重复消费

②消息幂等性：由消费者实现，表示即使多收到一条消息也不会让消息重复消费

解决办法：

- 保证消息幂等性，设置全局的id，在重试的过程中可以提前查询该逻辑是否已经执行过，则不会重复执行
- 数据库层面，加乐观锁、唯一主键约束、数据快照保证消息幂等性。类似于分布式锁





##### 15、mq消息顺序性

问题产生：mq可能会有集群，分区模型去放消息，对应不同的消费者去消费，消费者相当于不同的jvm，可能会导致消息顺序不一致

解决：消息投递到同一个mq，同一个分区模型，最终被同一个消费者消费，每条消息分配一个消息key计算hash（消费速率变慢，丧失并发的特性）





##### 17、多线程和mq

①多线程操作需要上下文切换，浪费cpu资源，影响业务的执行速度，可能会导致服务器崩溃

②mq使用异步方式完全解耦



##### 18、mq与redis如何保证一致

①删除redis缓存

②通过mq异步更新

③通过canal定义binlog文件







## Nginx

##### 1、nginx的作用

- 高性能http和反向代理服务器reject
- 反向代理、负载均衡、动静分离



##### 2、反向、正向代理

- 反向代理：代理端代理的是服务端
- 正向代理：代理端代理的是客户端

##### 3、负载均衡

- 负载均衡就是将代理服务器接收到的请求发送给各个服务器



##### 4、为什么Nginx性能高

- 异步非阻塞处理机制，运用了epoll模型，提供了一个队列，排队解决         


##### 5、ribbon和nginx区别

- nginx是服务端负载均衡器
- ribbon是客户端负载均衡器。从服务注册中心客户端上获取消息列表，缓存到本地实现负载均衡策略






# 分布式事务

##### 1、分布式事务存在的问题

rpc：dubbo、feign

分布式事务存在的问题：在rpc远程调用中，服务A调用服务B，然后服务A报错，服务A进行回滚，服务B报错不会回滚。

解决：通过服务A报错的状态码500 ，在服务B中如果=500，则手动的进行回滚A接口中的事务。



##### 2、分布式事务解决方案

单体：jta+atomikos

分布式架构：

①使用RocketMq解决分布式事务  采用事务消息

②使用Seata框架，但是响应速度会变慢。有tcc模式、AT模式



##### 3、seata解决分布式事务

AT：基于undolog日志逆向回滚。

sql写操作时，进行代理，在写操作前生成前置镜像（查sql），写操作后生成后置镜像（查sql）

将前置和后置进行存入undolog表

缺陷：可能会存在短暂的脏读问题



##### 4、CAP原理

C：一致性  A：可用性   P：分区容错性

- CP，必须要等网络恢复，进行数据同步。服务阻塞
- AP：不用等网络恢复，但是会存在数据不一致问题

##### 5、Base理论

- BA：基本可用性（允许损失部分可用性）   
- S：软状态（允许临时不一致状态 ）
- E：最终一致性（软状态之后）



##### 6、Seata

角色：

- TC事务协调者：协调全局事务提交和回滚
- TM事务管理器：开始全局事务、提交、回滚
- RM资源管理器：与TC交谈分支事务的注册和报告

事务解决方案：

①XA模式：强一致性，无业务入侵 。缺点：第一阶段锁定数据库资源，第二阶段才释放，性能差

②TCC模式：分阶段，最终一致，有业务入侵，需要人为编写try、Confirm和Cancel接口

③AT模式：分阶段，最终一致，无业务入侵

④SAGA模式：长事务模式，有业务入侵



##### 7、AT和XA区别

- XA模式第一阶段不提交事务，锁定资源。AT模式第一阶段直接提交，不锁定资源
- XA模式依赖数据库机制实现回滚。AT利用数据快照进行回滚
- XA强一致性。AT最终一致







# ElasticSearch

##### 1、什么是elasticsearch

- java语言开发基于Lucene的实时分布式搜索引擎、聚合分析、存储引擎
- 非关系型文档数据库，版本：7.6.2
- 日志系统：ELK日志数据分析
- 聚合查询



##### 2、es特点

- 天生分布式，比如：高性能（PB级别，1tb）、高可用、易扩展、易维护
- 跨平台。支持结构化




##### 2、倒排索引

主要解决问题：大数据搜索

为什么不使用b+树作为倒排索引结构：

- b+树支持千万级数据，树的深度增加导致读写性能差。不适合文本字段创建索引
- 没有遵循最左匹配原则的话，会导致索引失效



数据结构：(高效压缩、快速的编码解码)

- 单词索引term_index：加速查询速度
- 单词词典term_dictionary：所有的词条
- 倒排表posting_list：int有序数组，匹配了某个term的所有id集合。使用到的算法FOR（解决稠密数组），roaring bitmaps（解决稀疏数组）

字典树：





文档和词条

- 文档是每一条数据
- 文档中的内容分词后，得到的词语就是词条

正向索引

- 基于文档id创建索引。查询词条时必须找到文档，然后判断文档是否包含词条（根据文档查找词条）
- 可以给多个字段创建索引、排序快。非索引字段只能全表扫描

倒排索引

- 对文档内容进行分词

- 创建表，每行包括词条、文档id等信息。对（词条）创建索引，并记录词条所在的（id）信息

- 查询是先查询词条，再通过词条获取文档id，根据文档id获取文档

- 模糊查询是非常快，无法根据字段排序

  顺序：词条-->文档id-->文档


##### 3、mysql与elasticsearch对比

| **MySQL** | **Elasticsearch** | **说明**                                   |
| --------- | ----------------- | ---------------------------------------- |
| Table     | Index             | 索引(index)，就是文档的集合，类似数据库的表(table)         |
| Row       | Document          | 文档（Document）数据库中的行，JSON格式                |
| Column    | Field             | 字段（Field）域，JSON字段，类似数据库中的列（Column）       |
| Schema    | Mapping           | Mapping（映射）是约束类似数据库的表结构（Schema）          |
| SQL       | DSL               | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRU |

es在创建索引之前，可以什么都不定义，直接从索引中写数据。数据库中需要设置数据类型等



##### 4、索引库

mapping属性：对索引库文档的约束，可以类比为关系型数据库中的表结构

 type：字段数据类型

index：是否创建索引

analyzer：分词器类型

properties：字段的子字段

type常见类型：

字符串（text、keybord）........（和json一致）



##### 5、ES常见数据类型

- 数字类型：long integer short byte double
- keywords：适合精确查询
- text：每一个text都默认会被分词
- dates：时间类型
- geo-pont：经纬度
- geo-shape：多边形复杂形状



##### 6、自动、手动映射

- 自动映射：根据输入字段，自动创建mapping
- 手动映射：创建字段之前手动创建mapping，一般使用手动映射，因为自动映射可能会导致资源的浪费




##### 7、DSL查询

①查询所有：match_all

②全文检索查询：match_query\multi_match_query多字段查询

③精确查询：term不分词\range

④地理查询：geo_distance半径\geo_bounding_box矩形范围

⑤复合查询：bool\function_score



打分函数：

TF-IDF：在es5.0之前，会随着词频的增加越来越大

BM25:在es5.0之后，会随着词频增加而增大，增长曲线处于平衡

function_score（算分，排名）



term、match、keyword  区别

- term:不分词，检索类型
- match:分词
- keyword：字段类型



高亮：highlight





##### 8、ES支持哪些查询

按照语言：

- DSL查询：解决大部分的查询，全文检索
- script脚本查询：用于复杂场景查询
- Aggregations聚合查询：数据聚合查询
- SQL：不愿意去学DSL

按照场景：

精确查询、全文检索、组合查询、地理查询



①全文检索

什么是全文检索：会被分词的关键字

查询条件的边界界定：

- 搜索：有明确的查询条件边界
- 检索：研究相关度，没有明确的边界

match：匹配包含term（匹配和搜索词完全相同的结果）的子句

match_all：查询所有子句

multi_match：多字段查询

match_phrase：短语查询



②精确查询

term：查询完全相等的结果

terms：匹配和搜索词列表中任意项匹配的结果

range：范围查找



③组合查询

filter：过滤器，不参与算分

must：必须满足子句出现在匹配的文档中

must_not：必须不满足

should：多个条件默认满足一个条件

如果有must、filter，则should可以不满足任何条件

minimum_shoud_match:设置should里面需要满足的条件个数。



##### 9、聚合

1、桶聚合bucket

  按文档字段值分组：TermAggregation

  按日期分组：Date Histogram



2、度量聚合Metrics

计算值。最大值Max、最小值Min、平均值Avg、都求Stats



3、管道聚合

对结果再次进行聚合



##### 10、数据同步

①同步调用

数据变化时，先更新数据库数据。通过调用更新索引库接口去更新es中的数据。（耦合度高）

②异步通知

数据变化时，先更新数据库数据。发布消息给MQ，MQ监听消息，更新es中的数据。（依赖mq）

③监听binlog

监听mysql中的binlog，通过canal通知数据变更情况。（开启binlog，增加数据库负担）



##### 11、es集群

解决：

①海量数据存储问题：拆分，存储到多个节点

②单点故障问题：发片数据在不同节点备份



节点角色

master eligible：候选主节点

data：数据节点，crud

ingest：进行预处理（少用）

coordinating：路由请求负载均衡 到其他节点，返回给用户



##### 12、脑裂问题

当主节点与其他节点网络故障时，可能发生脑裂问题。

（网络恢复时，一个集群出现了两个主）

解决：通过控制选票资格，选票超过（eligible节点数量+1）/2



发布存储

elasticsearch会通过hash算法来计算文档应该存储到哪个分片，余数在哪 在哪分片

shard = hash（_routing）%number_of_shards

routing:默认文档id    索引库一旦创建，发片数量不能更改



发布式查询

分散阶段：coordinating node将查询请求方法给不同分片

收集阶段：将查询结果汇总到：coordinating node，整理并返回给用户。



##### 13、es故障转移

master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安。



##### 14、文档操作流程

- 初始化RestHighLevelClient

- 准备Request

- 准备Request.source()，也就是DSL

  ② 传入Request.source() . query(QueryBuilders.xx构造条件) 

- 发送请求

- 解析结果（参考JSON结果，从外到内，逐层解析）



##### 25、API

match查询：

- QueryBuilders.matchQuery()单字段查询    
- .mutiMatchQuery()多字段查询

精确查询：

- .termQuery()词条查询
- .rangeQuery()范围查询

布尔查询：

- .must()、.filter

分页：

- .source().from().size()

排序：

- .source().sort("排序字段",SortOrder.排序规则)

高亮：

- .highlighter(new HighlightBuilder().filed.requiredFiledMatch)

算分函数：

- ScoreFunctionBuilders.weightFactorFunction()

聚合：

- AggregationBuilders.terms.filed.size








# 生产环境

##### 1、生产环境cpu飙高

问题：

- 死循环（解决：设置睡眠时间）
- CAS自旋锁（解决：控制循环次数）
- 服务器被DDOS攻击（流量、模拟请求）  解决：通过限流、ip黑名单、图形验证码防止ddos攻击
- 阿里云redis被注入挖矿程序（redis端口号不要让外网访问）



如何定位解决：

windows：

1. 使用jvisualvm工具中哪个名称的线程使用率最高，找到具体发生cpu飙高的代码
2. 分析进程中哪个线程cpu使用率最高（创建线程池 ，给线程配置名称




linux：

1. 使用top -c定位 
2. 使用top -Hp 进程号 找到对应的线程
3. 使用jstack命令，查看堆栈信息（进制转换） 就可以查看到哪一部分代码出现了问题



开发环境：

1. 使用服务监控系统
2. 云cpu飙高到一定的阈值 发送邮件警告
3. 服务器如果是集群状态。首先发消息给运维人员哪台服务器节点cpu飙高192.168.110.110
4. 通知开发人员配合排查服务器，哪个线程飙高






##### 2、生产环境报错

如何定位：

- 查看日志排查tail，集群较少
- 项目中写一个aop拦截错误日志，将错误内容上报给mq服务端，消费者获取错误内容，主动调用微信微信公众号接口，通知给开发人员，通过apm系统的skywalking追踪链可以看具体错误信息




##### 3、服务器宕机

- 在服务器上安装keepalived监听java进程，如果宕机就自动尝试重启java进程
- 如果重启了多次还是失败，可以使用容器扩容（docker或k8s）




##### 4、调用接口  服务器不响应

- 因为http请求是同步的，如果没有及时的响应给客户端，客户端就会认为超时
- 服务器端调用网络连接，比如说调用征信接口
- 查询db慢，放在redis缓存。将耗时的代码，放在mq中，异步的调用接口




##### 5、开发遇见的难题

- insert表格，导出数据的时候发生内存溢出，数据量太大了，增加jvm的堆内存
- 我们公司提供一个接口，他的公司调用我们公司接口的过程中，响应超时了，在请求的过程中，导致我们的接口会重复的执行业务逻辑。解决：全局id业务上防止重复，在db层面加唯一主键约束。幂等性判断
- 有一段 代码出现了死循环，在生产环境中一直报cpu飙高问题，被监控系统所监控，cpu达到百分之70就自动报警，告诉当前服务器端哪个线程出现了问题
- 前后端分离项目，出现跨域问题。在请求头上写一个响应告诉客户端允许跨域。通过nginx解决跨域
- 生产环境中的定时任务，在集群的环境下防止定时任务重复执行。解决：在打jar包的时候，加上一个开关，只让一个jar包执行定时任务。使用分布式调度xxl-job最终分片执行



##### 7、微信v2、v3

- 使用的是v3
- 请求参数不一致，v2是xml    v3是json
- 提交方式不一样，v2是post   v3是标准的restful风格请求方式
- 签名方式不一样，v2是md5    v3是非对称加密



##### 6、日志如何处理

①传统环境：使用tail  -100f xx.log查看日志。存在缺陷：如果是集群则需要在每台服务器上进行查看日志

②分布式日志解决方案：ELK+kafka

- E：存储日志信息   L：logstash搬运工    K:kibana可视化系统查询日志


1. 在每一台服务器中运行logstash搬运工插件程序进行读取日志文件
2. 再以json的格式输出到es中，es再通过kibanna可视化

缺点：服务器扩容，需要再次在服务器中安装logstash



1. 在项目中写一个aop去拦截日志
2. 将日志输出到kafka中，logstash去订阅kafka中的message
3. 再将日志输出到logstash中，以json格式数据输出到es服务器中。使用kibanna可视化系统观看

缺点：延迟、aop的每一步通知都会进行kafka消息的投递  （同步：导致响应过慢）



解决：

1. 将aop中的前置通知写入并发队列缓存中，再开启一个缓存单独的异步将日志投递到kafka
2. logstash去订阅kafka中的message
3. 再将日志输出到logstash中，以json格式数据输出到es服务器中。使用kibanna可视化系统观看



##### 7、前端到后端整体流程

1. 微服务架构，前后端分离，前端vue，后端写接口。，通过vue调用接口
2. 后端需要编写接口文档swagger，方便前端工程师测试
3. 为了保证接口安全，整合ddos  高防服务器防止接口被攻击（黑名单、白名单、接口图形验证码）
4. 高仿服务器转发到不同的网关。网关对接口进行限流（服务熔断、降级、隔离、服务保护、配置接口跨域问题）
5. 网关再发给不同的服务
6. 如果接口是开放接口，需要申请对应秘钥



##### 8、高并发解决方案

前端：

cdn：在外网中传输数据有带宽限制。静态资源占带宽80%。缺点：刷新缓存缺陷。如果更改一个静态页面，各个节点也要刷新

1. 动静分离，将静态资源放入第三方的cdn中。比如阿里云oss等，cdn在全国都有节点， 用户就近访问
2. 压缩静态资源.min，减少带宽占用



后端：

1. jvm：jvm实现参数调优，减少gc回收频率，减少stw问题，选择合适垃圾回收器
2. redis：使用redis作缓存减少数据库的访问压力（雪崩...一致问题）
3. mysq：定义慢查询、建立索引、分表分库
4. mq：流量削峰问题（异步），为了避免消息堆积  建议mq消费者集群和批量消费消息，当流量突然大的时候整合k8s进行快速的扩容与缩容
5. gateway：利用网关层面对服务器接口进行保护，通过限流防止大量请求的冲击
6. hystrix：对不能访问的服务进行熔断



运维：

1. 整合k8s进行弹性扩容和缩容
2. 整合SkyWalking，分布式跟踪系统实现服务监控。当cpu飙高等问题能够提前预防，底层使用的是agent代理
3. elk+kafka采集分布式系统日志



访问：

1. 通过ddos高防服务器，转发到真正服务器
2. 图形验证码，防止机器模拟攻击




##### 9、内存泄露问题

内存泄露：堆内存通过某种原因无法释放

案例：

- threadLocal
- hashMap：key是强引用，java回收机制会对没有引用的堆内存对象进行回收，会导致强引用无法被回收

排查：通过java虚拟机，查看那个对象占用空间大












































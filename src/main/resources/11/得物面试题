1、kafka的基础架构，kafka消费者数量可以大于分区数么？大于怎么办？kafka如何保证消息不丢失？kafka怎么将数据持久化？
kafka是一个分布式处理平台，它的集群由一个或者多个服务器（broker：负责接收和存储来自生产者的消息，并将消息推送给消费者）组成
topic：用于消息分类，每个topic可以分成多个区（partition）。每个分区可以有多个副本，实现故障转移
partition：每个分区是一个有序的不可变的消息序列。每个消息都在分区中有一个唯一的偏移量（offset），用于标识消息位置。每一个分区的消息只能被一个消费者处理
producer：生产者可以选择将消息发送到特地的topic跟分区。生产者可以使用不同的策略（轮询，哈希）
consumer：消费者可以加入消费组，每个组内的消费者可以消费不同topic中不同的分区。消费者负责管理自己的偏移量，以确保消息的消费进度
消息传递模型：发布订阅模式：生产者将消息发布到特定的topic，消费者丁炔特定的topic    分区和并行：通过分区kafka可以实现高吞吐和并发
存储机制:日志文件，kafka将消息存储在磁盘日志文件中，可以配置保留时间
复制机制：每个分区可以有多个副本，每个分区有一个领导副本，负责处理所有的读写请求，其它副本同步领导数据
容错机制：broker通过心跳检测监控消费者的活跃状态。如果领导失败，kafka会选择一个副本作为新的领导者。kafka维护了一个ISR列表，只有在列表的副本才能被选为新的领导者。

kafka的消费者数量原则上是可以大于分区数的。
因为Kafka 主题的分区数在创建后不能更改，因此在创建时应合理规划。如果分区数太少，消费者组中多余的消费者将无法参与消费，导致资源浪费。适当增加分区数量可以提高消费者的并行度，从而缓解数据倾斜问题。
如果出现了这样的情况可以通过优化单个消费者的处理能力来提高消息处理效率（并行消费多线程处理，批量处理异步提交，实时监控）

kafka通过持久化存储、复制机制、生产者消息确认机制，消费者手动提交偏移量保证数据不丢失。
kafka使用日志文件来存储消息。会将每个主题每个分区的数据存储在一个或者多个日志文件中（kafka未来便于管理，将每个分区的日志文件分割成多个日志段。当一个文件大小超过1GB会创建一个新的日志段）
生产者将消息发送到broker时，会将消息写到对应的分区日志中，在将日志文件同步到磁盘。 可以配置参数：配置日志同步磁盘之前可以累积的最大消息数，最大时间间隔，日志保留时间，日志段大小。

2、说一下B+数的结构，空值会走索引么？
B+数是一种多路平衡查找树。在b+树中所有数据都记录在叶子节点上，所有的叶子节点通过指针链接成一个有序链表。非叶子节点只记录所有关键字跟指向子节点的指针。

3、口述b+数的层级遍历
层级遍历是一种按照树的高度逐层访问的遍历方式。通常使用队列类实现。类似广度优先算法：先把根节点放入队列，当队列不为空的时候，取出第一个节点，然后查询该节点连接的所有节点，如果这个节点不是叶子节点，则将它的子节点依次入队，然后重复直到队列数据被取完。

4、jvm内存模型？栈的生命周期？栈的大小是多少？
程序计数器（记录当前线程执行的字节码指令地址，每个线程有独立的程序计数器。如果是本地方法则计数器值为空）、
虚拟机栈（线程私有的，每个java方法执行的时候都会创建）、本地方法栈（每个本地方法执行的时候创建）、
堆（被所有线程共享，唯一作用就是存放对象实例，是垃圾处理器管理的主要区域，所以也被称为GC堆）
方法区（永久代、元空间：各个线程共享的区域，存储已经加载的类信息、常量池、静态变量、编译后的代码数据，java8之后内存不在分配在堆中间。而是使用本地内存）
运行常量池；（方法区的一部分。用于存储字符串常量，数字常量，接口，类，方法的全限定名）
每个线程都有一个私有的虚拟机栈，它会随着方法的调用和返回创建跟销毁。所以它的生命周期跟线程是一样的。
线程生命周期：（新建、就绪（start（）开启新线程并且调用run（））、运行中（run（））、阻塞、等待（object.wait（）、Thread.join（）等待。object.notifyAll（）、object.notify（）会唤醒重新就绪）、超时等待（之后会自动恢复到就绪状态）、结束）
栈的大小是可以通过jvm参数-Xss配置的，默认256kb-1MB之间

5、volatile作用？
volatile是java中的一个关键字,用于修饰变量。确保变量的可见性和禁止指令重排序。主要用于多线程环境中的变量共享，确保线程之间的内存可见性。但是不能保证原子性。
使用场景:单例模式的双重检查机制确保单例实例的可见性
单例模式：确保一个类只有一个实例，通过控制类的构造方法防止外部代码随意创建多个对象。通过静态方法或者全局变量的方式允许系统其它组件方便的访问该唯一实例。

6、synchronized底层实现？让你实现一个锁你怎么做？
synchronized关键字解决的是多个线程之间访问资源的同步性，保证同一时刻被修饰的代码块或者方法只有一个线程执行。
原子性，可见性，有序性，重入性（锁对象的时候有一个计数器）
它的底层是依赖jvm虚拟机实现，java虚拟机给每个对象都设置了一个监听器monitor用于检测并发代码的重入。当方法调用时候会检查有没有acc_synchronized标记 如果有则先持有monitor 当jvm执行到monitorenter指令时候会把锁的计数器+1，当执行monitorexit指令时会计数器-1
synchronized锁升级：无锁
---偏向锁（对象头中存储偏向线程id，如果有另外的线程访问则撤销偏向锁升级为轻量级锁）
---轻量级锁（对象头中存储的是锁记录的指针。当存在锁竞争，会使用自旋锁来避免线程阻塞，等待锁释放，如果等待线程数量比较多或者时间过长则升级为重量级锁）
---重量级锁（对象头中存储的是同步队列的指针被多个线程竞争，线程阻塞，直到锁被释放）
让我实现一个锁的话我会参考：
lock是一个接口，比如ReentrantLock是lock的实现类：可重入，公平锁，锁中断，尝试加锁和条件变量。提供了更加灵活的锁操作。
定义boolean变量，定义0为未上锁，定义锁的计数器，记录当前持有锁的线程。判断当前线程后进入锁+1否则就等待。

死锁发生的原因？怎么避免？
死锁是多个进程在执行过程中因争夺资源而造成的一种僵局。
死锁的发生要满足四个条件：1。互斥条件（资源一次只能被一个线程占用）2.占有并等待（一个进程已经占有了资源，但是又申请了新的资源，而新的资源被其它进程占有，导致该进程等待）3。不剥夺条件（资源只能由占有它的线程自己释放，不能被其它线程强行剥夺）
4。循环等待（存在一个线程的环路，每个进程都在等待下一个进程占有的资源）
一般来说都是在请求资源的时候设置超时时间，超时则自动释放。还有在多线程环境下可以进行对锁进行编号或者排序，要求说所有线程在获取锁的时候按顺序进行

7、redis什么时候会阻塞？需要注意什么？lur底层数据结构
一般情况下redis是非阻塞的，但是redis提供了一些阻塞命令
如果从列表的头部或者尾部弹出元素，或者从有序集合中弹出最大或者最小值的时候列表为空则会阻塞。
redis处理大对象的时候也可能导致阻塞。
执行复杂查询或者涉及大量数据查询的时候也可能导致阻塞。
redis做持久化操作RDB跟AOF的时候虽然是创建一个子进程来操作。但是，生成快照的时候可能占用大量资源会影响主线程的性能。
redis内存不足触发淘汰策略的时候也可能阻塞。
lur数据结构：哈希表+双向连表；其中hash表存储key到链表的映射，用于快速查找缓存项。链表用户维护缓存项的使用顺序。
为啥用hashTable不用concurrentMap是因为table所有方法都是同步的，在多线程环境下更容易理解维护。map需要更多的代码来确保操作的一致性。map虽然性能高 但是在这个场景下没有必要。并且table是java1.0出现的，concurrentMap是1.5才引入。

8、Mysql三个日志是什么：
undoLog：记录操作前的数据快照。用于事务回滚
readLog：事务提交之前记录数据页的修改（事务id，操作类型，表名，行id，修改前后的值）属于存储引擎层
binLog：事务提交之后记录sql语句或者行级别的修改。属于server层
Error Log：错误日志
你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool中。后续的查询或者修改都是直接从buffer Pool中更新。然后会把相关操作记录到undoLog中

9、12306抢票系统的库存模块怎么设计？
1.需要设计库存表以及订单表
2.高并发处理：可以用redis分布式锁保证对库存修改是原子的 还可以在数据库表中添加版本号字段，使用乐观锁确保数据的一致性，可以在更新库存的时候使用行锁确保事务的隔离性
3.性能优化：使用redis缓存库存信息，使用消息队列处理订单创建跟库存更新，减少系统响应时间
4.容错机制：保证订单跟库存操作幂等性。添加重试策略避免无限重试
5.降级策略：只允许少量请求通过。或者返回空数据或者提示信息。
6.监控日志：实时监控qps，响应时间，错误率等。
10、MVCC机制：
MVCC是多版本并发控制，主要提高数据库性能的机制。允许多个事务同时读取和写入数据。、
Mvcc机制是实际上是通过readView + undoLog日志实现的。 其中readView负责可见性规则，undoLog负责保存历史快照。
查询一条记录时候会先获得一个事务版本id，然后获取readView。通过对比版本id确定该数据是否可读。
readView：trx_ids（未提交的事务版本号集合）low_limit_id（集合中最大值+1）up_limit_id（集合中最小值）
数据隐式字段：单调递增的row_id 最后一次修改该数据事务的trx_id  roll_pointer 指向undoLog日志

11、ribbitMq的基础架构，怎么刷盘？
ribbitMQ的工作流程：生产者连接到broker并创建一个channel（渠道），通过这个channel，生产者可以声明一个exchange，并向这个exchange发送消息。同时消费者也可以通过channel声明一个或者多个队列。并设置exchange与队列的绑定规则。
当exchange收到消息后，会根据绑定规则路由到对应的队列，最后消费中可以通过channel从队列中取出消息进行处理。
刷盘方式可以分为同步刷盘和异步刷盘两种模式：
同步刷盘意味着每次写入操作都会等待数据完全写入磁盘后才返回确认信息。这种方式提供了更强的数据持久性保证，因为只有在数据成功落盘后，生产者才会收到确认。然而，由于每次写入都需要等待磁盘 I/O 操作完成，因此同步刷盘会显著增加写入操作的延迟，影响整体吞吐量
异步刷盘则是在消息写入内存后立即返回确认信息，而将实际的磁盘写入操作推迟到后续的批量刷盘过程中。这种方式减少了 I/O 等待时间，提高了消息的吞吐能力，但牺牲了数据的持久性。如果在数据尚未刷盘时发生服务崩溃，可能会导致消息丢失。
消息的刷盘操作可以在多个阶段被触发：
生产者发送消息时：如果消息被标记为持久化（delivery_mode=2），则 RabbitMQ 会在消息进入队列后触发刷盘操作
队列声明时配置 Lazy （惰性队列："queue-mode":"lazy"）模式：此时所有消息都会直接写入磁盘，而不论其是否被标记为持久化
定期刷盘：RabbitMQ 会定期将内存中的消息批量写入磁盘，以平衡性能与持久性需求
交换机：direct：根据key将消息发送到指定的队列中。fanout（广播）：将消息发送给与之绑定的所以队列。topic：将消息通过规则匹配发送给相应的队列

12、redis和mysql如何保证数据一致性
1、先更新数据库再删除redis 2、先删除缓存，再更新数据库，再删除缓存 3、使用canal监听bigLog日志自动更新redis 4、使用redisson分布式锁 写操作加锁 5、事务补偿机制 redis不支持事务需要手动失效补偿逻辑（将数据库更新的数据删除或者通过mq重试）

13、ThrealLocal是什么，它的实现原理是啥？thealLocal内存泄漏问题？
ThrealLocal是java提供的一个类，用于再每个线程储存独立的变量副本。它的实现原理依赖与ThrealLocalMap。每个thread对象都有一个threadLocalMap实例
key是弱引用，value是强引用，key被回收但是value还在就会导致内存泄漏。每次使用完都调用remove方法。
如果threadLocal的key为强引用，那么当实例不再被外部代码引用时无法被垃圾回收器回收，就会一直占用内存。
但是用static修饰会减少内存泄漏风险：因为被修饰的实例是静态的，使用该实例的每个线程都会共享一个变量。在整个应用程序中只会创建一次，如果没有被修饰的话，每个线程都会创建一个新的实例。但是在线程池中使用的话复用的线程会保留之前的threadLocal值就会导致内存泄漏。

14.什么是受检异常和非受检异常？
受检异常是在编译过程中必须处理的异常，必须通过try-catch捕获异常或者使用throws声明，表示可以预见的异常
非受检异常通常是编程错误导致的异常：数组越界，空指针，非法参数。运行时异常等

15.mysql的行锁到底是锁的什么？
锁的是这行数据的索引记录。有唯一索引就锁唯一索引，有普通索引就锁普通索引否则就锁主键索引。行锁分共享锁（允许多个事务同时读，但是不允许修改 lock in share mode）跟排他锁（只允许一个事务读写 for update）

16.mysql数据库cpu飙升的话怎么处理：
通过top命令找到查看各个进程资源使用情况。
开启慢查询日志：slow_query_long=on 设置慢查询时间阈值：long_query_time = 1
explan分析执行计划：type：大于range （index全索引扫描，all全表扫描，ref对于前一个表的每一行） key：实际使用的索引
优化sql，调整msql配置：增加缓存大小（query_cache_size  innodb_buffer_pool_size） ，调整线程池大小（thread_pool_size） ，增大连接数（max_connections）
==================
1、kafka消费堆积怎么办？重试失败怎么办？
2、cpu飙高，内存飙高怎么排查处理？
3、当线程池处理任务时出现了异常会发生什么。

